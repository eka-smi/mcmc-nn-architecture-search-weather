{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObbCu09steEC9edDwTyxxN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eka-smi/mcmc-nn-architecture-search-weather/blob/main/Project_random_walk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **–ü—É–Ω–∫—Ç B**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "H5glsa0AvBzF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYMuPEfqqya3"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict, Any, Optional\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eKDGbSE3wEjx",
        "outputId": "0270013b-3c64-4eb9-97cc-b78f18d37756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        output_dim: int,\n",
        "        arch: List[int],\n",
        "        activation: str = \"relu\",\n",
        "        dropout: float = 0.0\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        act_layer = {\n",
        "            \"relu\": nn.ReLU,\n",
        "            \"tanh\": nn.Tanh,\n",
        "            \"gelu\": nn.GELU,\n",
        "            \"sigmoid\": nn.Sigmoid\n",
        "        }.get(activation.lower(), nn.ReLU)\n",
        "\n",
        "        layers = []\n",
        "        prev = input_dim\n",
        "\n",
        "        for width in arch:\n",
        "            layers.append(nn.Linear(prev, width))\n",
        "            layers.append(act_layer())\n",
        "            if dropout > 0:\n",
        "                layers.append(nn.Dropout(dropout))\n",
        "            prev = width\n",
        "\n",
        "        layers.append(nn.Linear(prev, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "xzqfftL2wL7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(input_dim=10, output_dim=1, arch=[32, 16], activation=\"relu\", dropout=0.1)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vodrKJ1xwcCk",
        "outputId": "726d5f0b-69e0-4c5b-a539-e0b3c124d020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=10, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.1, inplace=False)\n",
            "    (6): Linear(in_features=16, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_loss(model: nn.Module, loader: DataLoader, loss_fn) -> float:\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_count = 0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # —É–º–Ω–æ–∂–∞–µ–º –Ω–∞ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞, —á—Ç–æ–±—ã –ø–æ—Ç–æ–º —á–µ—Å—Ç–Ω–æ —É—Å—Ä–µ–¥–Ω–∏—Ç—å\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        total_count += x.size(0)\n",
        "\n",
        "    return total_loss / max(total_count, 1)\n"
      ],
      "metadata": {
        "id": "KA-XngusLG-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_get_val_loss(\n",
        "    arch: List[int],\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    input_dim: int,\n",
        "    output_dim: int,\n",
        "    task: str = \"regression\",     # \"regression\" –∏–ª–∏ \"classification\"\n",
        "    activation: str = \"relu\",\n",
        "    lr: float = 1e-3,\n",
        "    epochs: int = 10,\n",
        "    weight_decay: float = 0.0,\n",
        "    dropout: float = 0.0,\n",
        "    verbose: bool = False\n",
        ") -> float:\n",
        "\n",
        "\n",
        "    # 1) —Å–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ\n",
        "    model = MLP(input_dim, output_dim, arch, activation=activation, dropout=dropout).to(device)\n",
        "\n",
        "    # 2) –≤—ã–±–∏—Ä–∞–µ–º loss –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏\n",
        "    if task == \"regression\":\n",
        "        # —Ä–µ–≥—Ä–µ—Å—Å–∏—è: y –æ–±—ã—á–Ω–æ float, shape [batch, 1] –∏–ª–∏ [batch, output_dim]\n",
        "        loss_fn = nn.MSELoss()\n",
        "    elif task == \"classification\":\n",
        "        # –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: y –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å LongTensor shape [batch]\n",
        "        # –∞ –≤—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏ shape [batch, num_classes]\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "    else:\n",
        "        raise ValueError(\"task must be 'regression' or 'classification'\")\n",
        "\n",
        "    # 3) –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\n",
        "    # weight_decay ‚Äî L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    # 4) –æ–±—É—á–µ–Ω–∏–µ\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if verbose and ep == epochs - 1:\n",
        "            # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º val_loss –≤ –∫–æ–Ω—Ü–µ, —á—Ç–æ–±—ã –Ω–µ —Å–ø–∞–º–∏—Ç—å\n",
        "            val_loss = evaluate_loss(model, val_loader, loss_fn)\n",
        "            print(f\"[arch={arch}] epoch={ep+1}/{epochs}, val_loss={val_loss:.6f}\")\n",
        "\n",
        "    # –∏—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
        "    val_loss = evaluate_loss(model, val_loader, loss_fn)\n",
        "    return float(val_loss)\n"
      ],
      "metadata": {
        "id": "y-BgqG4aLOLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def propose_architecture(\n",
        "    arch: List[int],\n",
        "    min_units: int,\n",
        "    max_units: int,\n",
        "    step: int = 8\n",
        ") -> List[int]:\n",
        "    \"\"\"\n",
        "    Proposal –¥–ª—è Metropolis-Hastings:\n",
        "    - –≤—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —Å–ª–æ–π i\n",
        "    - –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–º–µ–Ω–∏—Ç—å arch[i] –Ω–∞ +/- step\n",
        "    - –µ—Å–ª–∏ —É—à–ª–∏ –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã => –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É (—Ç–æ –µ—Å—Ç—å \"–Ω–µ —Å–¥–µ–ª–∞–ª–∏ —Ö–æ–¥\")\n",
        "\n",
        "    –ü–æ—á–µ–º—É —ç—Ç–æ —É–¥–æ–±–Ω–æ:\n",
        "    - –í—Å–µ —Ä–µ–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã –∏–º–µ—é—Ç –æ–±—Ä–∞—Ç–Ω—ã–π –ø–µ—Ä–µ—Ö–æ–¥ —Å —Ç–æ–π –∂–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é.\n",
        "    - –ú—ã –Ω–µ –¥–µ–ª–∞–µ–º \"–æ–±—Ä–µ–∑–∫—É\" (clamp) –¥–æ max/min —Ç–∞–∫, —á—Ç–æ–±—ã —Å–ª—É—á–∞–π–Ω–æ –ø–æ–ª—É—á–∏–ª—Å—è\n",
        "      —à–∞–≥ –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (—ç—Ç–æ –º–æ–∂–µ—Ç –Ω–∞—Ä—É—à–∞—Ç—å —Å–∏–º–º–µ—Ç—Ä–∏—é, –µ—Å–ª–∏ bounds –Ω–µ –∫—Ä–∞—Ç–Ω—ã step).\n",
        "    \"\"\"\n",
        "    new_arch = arch.copy()\n",
        "\n",
        "    i = random.randrange(len(new_arch))         # –∫–∞–∫–æ–π —Å–ª–æ–π –º–µ–Ω—è–µ–º\n",
        "    direction = random.choice([-1, +1])         # –≤ –∫–∞–∫—É—é —Å—Ç–æ—Ä–æ–Ω—É\n",
        "\n",
        "    cand = new_arch[i] + direction * step       # –∫–∞–Ω–¥–∏–¥–∞—Ç\n",
        "\n",
        "    # –ï—Å–ª–∏ –≤—ã—à–ª–∏ –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã ‚Äî –¥–µ–ª–∞–µ–º \"–Ω—É–ª–µ–≤–æ–π —Ö–æ–¥\"\n",
        "    # (—Ü–µ–ø—å –º–æ–∂–µ—Ç –∏–Ω–æ–≥–¥–∞ —Å—Ç–æ—è—Ç—å –Ω–∞ –º–µ—Å—Ç–µ ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ)\n",
        "    if cand < min_units or cand > max_units:\n",
        "        return new_arch  # –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
        "\n",
        "    new_arch[i] = int(cand)\n",
        "    return new_arch\n"
      ],
      "metadata": {
        "id": "rw6U1Y0-Qryv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arch = [32, 16, 64]\n",
        "for _ in range(10):\n",
        "    print(arch, \"->\", propose_architecture(arch, min_units=8, max_units=128, step=8))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbhz_Uy5Qu90",
        "outputId": "ad71ecb5-6732-4c27-d352-c41b681eeaea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[32, 16, 64] -> [32, 16, 56]\n",
            "[32, 16, 64] -> [40, 16, 64]\n",
            "[32, 16, 64] -> [24, 16, 64]\n",
            "[32, 16, 64] -> [24, 16, 64]\n",
            "[32, 16, 64] -> [32, 16, 56]\n",
            "[32, 16, 64] -> [32, 16, 72]\n",
            "[32, 16, 64] -> [24, 16, 64]\n",
            "[32, 16, 64] -> [24, 16, 64]\n",
            "[32, 16, 64] -> [24, 16, 64]\n",
            "[32, 16, 64] -> [32, 16, 56]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class MCMCConfig:\n",
        "    \"\"\"\n",
        "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—à–µ–π MCMC-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.\n",
        "    \"\"\"\n",
        "    K: int = 3                 # —á–∏—Å–ª–æ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤ (–≤ –ø—É–Ω–∫—Ç–µ b —Ñ–∏–∫—Å–∏—Ä—É–µ–º –≥–ª—É–±–∏–Ω—É)\n",
        "    min_units: int = 8\n",
        "    max_units: int = 128\n",
        "    step: int = 8              # –Ω–∞ —Å–∫–æ–ª—å–∫–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –º–µ–Ω—è–µ–º —à–∏—Ä–∏–Ω—É —Å–ª–æ—è –∑–∞ –æ–¥–∏–Ω proposal\n",
        "    iters: int = 30            # —Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ MCMC –¥–µ–ª–∞–µ–º\n",
        "\n",
        "    # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:\n",
        "    # –º–∞–ª–µ–Ω—å–∫–∞—è => –ø–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞ –ø—Ä–∏–Ω–∏–º–∞–µ–º —Ç–æ–ª—å–∫–æ —É–ª—É—á—à–µ–Ω–∏—è (–∂–∞–¥–Ω—ã–π –ø–æ–∏—Å–∫)\n",
        "    # –±–æ–ª—å—à–∞—è => —á–∞—Å—Ç–æ –ø—Ä–∏–Ω–∏–º–∞–µ–º —É—Ö—É–¥—à–µ–Ω–∏—è (–±–æ–ª—å—à–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è)\n",
        "    temperature: float = 0.05\n",
        "\n",
        "    # –ë—é–¥–∂–µ—Ç –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ–¥–Ω—É –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É (—ç—Ç–æ –≥–ª–∞–≤–Ω–∞—è \"—Ü–µ–Ω–∞\" –ø–æ –≤—Ä–µ–º–µ–Ω–∏)\n",
        "    train_epochs: int = 10\n",
        "    lr: float = 1e-3\n",
        "\n",
        "    activation: str = \"relu\"\n",
        "    dropout: float = 0.0\n",
        "    weight_decay: float = 0.0\n",
        "\n",
        "    task: str = \"regression\"   # –∏–ª–∏ \"classification\"\n",
        "\n",
        "    # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ:\n",
        "    # –µ—Å–ª–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–æ–≤—Ç–æ—Ä–∏–ª–∞—Å—å, –º–æ–∂–Ω–æ –Ω–µ –æ–±—É—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ, –∞ –≤–∑—è—Ç—å —Å—Ç–∞—Ä—ã–π val_loss.\n",
        "    cache: bool = True\n"
      ],
      "metadata": {
        "id": "tJzj56i2X0Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metropolis_hastings_arch_search(\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    input_dim: int,\n",
        "    output_dim: int,\n",
        "    init_arch: List[int],\n",
        "    cfg: MCMCConfig,\n",
        "    verbose: bool = True\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ú–µ—Ç—Ä–æ–ø–æ–ª–∏—Å–∞‚Äì–ì–∞—Å—Ç–∏–Ω–≥—Å–∞ –ø–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤—É –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.\n",
        "\n",
        "    –°–æ—Å—Ç–æ—è–Ω–∏–µ —Ü–µ–ø–∏: arch = [n1, ..., nK]\n",
        "    –≠–Ω–µ—Ä–≥–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è: L(arch) = val_loss –ø–æ—Å–ª–µ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
        "\n",
        "    –¶–µ–ª–µ–≤–∞—è \"–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å\" –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:\n",
        "        pi(arch) ‚àù exp( - L(arch) / T )\n",
        "\n",
        "    –¢–æ–≥–¥–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ú–µ—Ç—Ä–æ–ø–æ–ª–∏—Å (–ø—Ä–∏ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–º proposal):\n",
        "        alpha = min(1, exp( -(L_new - L_old)/T ))\n",
        "    \"\"\"\n",
        "\n",
        "    assert len(init_arch) == cfg.K, \"init_arch –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –¥–ª–∏–Ω—É K (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–ª—è –ø—É–Ω–∫—Ç–∞ b).\"\n",
        "\n",
        "    # loss_cache: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —É–∂–µ –ø–æ—Å—á–∏—Ç–∞–Ω–Ω—ã–µ val_loss –¥–ª—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä,\n",
        "    # —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ.\n",
        "    loss_cache: Dict[Tuple[int, ...], float] = {}\n",
        "\n",
        "    def get_loss(arch: List[int]) -> float:\n",
        "        \"\"\"\n",
        "        –í–æ–∑–≤—Ä–∞—â–∞–µ–º val_loss –¥–ª—è arch, –∏—Å–ø–æ–ª—å–∑—É—è –∫–µ—à –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.\n",
        "        \"\"\"\n",
        "        key = tuple(arch)\n",
        "\n",
        "        if cfg.cache and key in loss_cache:\n",
        "            return loss_cache[key]\n",
        "\n",
        "        val_loss = train_and_get_val_loss(\n",
        "            arch=arch,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            input_dim=input_dim,\n",
        "            output_dim=output_dim,\n",
        "            task=cfg.task,\n",
        "            activation=cfg.activation,\n",
        "            lr=cfg.lr,\n",
        "            epochs=cfg.train_epochs,\n",
        "            weight_decay=cfg.weight_decay,\n",
        "            dropout=cfg.dropout,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        if cfg.cache:\n",
        "            loss_cache[key] = val_loss\n",
        "\n",
        "        return val_loss\n",
        "\n",
        "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ü–µ–ø–∏\n",
        "    current_arch = init_arch.copy()\n",
        "    current_loss = get_loss(current_arch)\n",
        "\n",
        "    # –•—Ä–∞–Ω–∏–º –ª—É—á—à–∏–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –æ—Ç–¥–µ–ª—å–Ω–æ\n",
        "    best_arch = current_arch.copy()\n",
        "    best_loss = current_loss\n",
        "\n",
        "    history = []\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Start: arch={current_arch}, val_loss={current_loss:.6f}\")\n",
        "\n",
        "    for t in range(cfg.iters):\n",
        "        # 1) –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è\n",
        "        proposed_arch = propose_architecture(\n",
        "            current_arch,\n",
        "            min_units=cfg.min_units,\n",
        "            max_units=cfg.max_units,\n",
        "            step=cfg.step\n",
        "        )\n",
        "\n",
        "        # 2) –û—Ü–µ–Ω–∏—Ç—å \"—ç–Ω–µ—Ä–≥–∏—é\" –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
        "        proposed_loss = get_loss(proposed_arch)\n",
        "\n",
        "        # 3) –ü–æ—Å—á–∏—Ç–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∏–Ω—è—Ç–∏—è\n",
        "        # delta < 0 => —Å—Ç–∞–ª–æ –ª—É—á—à–µ => –ø—Ä–∏–Ω–∏–º–∞–µ–º –≤—Å–µ–≥–¥–∞\n",
        "        # delta > 0 => —Å—Ç–∞–ª–æ —Ö—É–∂–µ => –ø—Ä–∏–Ω–∏–º–∞–µ–º –∏–Ω–æ–≥–¥–∞\n",
        "        delta = proposed_loss - current_loss\n",
        "\n",
        "        if delta <= 0:\n",
        "            accept_prob = 1.0\n",
        "        else:\n",
        "            # exp(-delta/T): –µ—Å–ª–∏ T –º–∞–ª–µ–Ω—å–∫–æ–µ, —Ç–æ —É—Ö—É–¥—à–µ–Ω–∏—è –ø–æ—á—Ç–∏ –Ω–µ –ø—Ä–∏–Ω–∏–º–∞—é—Ç—Å—è\n",
        "            accept_prob = math.exp(-delta / max(cfg.temperature, 1e-12))\n",
        "\n",
        "        # 4) –ú–æ–Ω–µ—Ç–∫–∞\n",
        "        accepted = (random.random() < accept_prob)\n",
        "\n",
        "        # 5) –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ü–µ–ø–∏\n",
        "        if accepted:\n",
        "            current_arch = proposed_arch\n",
        "            current_loss = proposed_loss\n",
        "\n",
        "        # 6) –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ\n",
        "        if current_loss < best_loss:\n",
        "            best_loss = current_loss\n",
        "            best_arch = current_arch.copy()\n",
        "\n",
        "        # 7) –õ–æ–≥–∏—Ä—É–µ–º —à–∞–≥\n",
        "        history.append({\n",
        "            \"iter\": t + 1,\n",
        "            \"current_arch\": current_arch.copy(),\n",
        "            \"current_loss\": float(current_loss),\n",
        "            \"proposed_arch\": proposed_arch,\n",
        "            \"proposed_loss\": float(proposed_loss),\n",
        "            \"accepted\": accepted,\n",
        "            \"accept_prob\": float(accept_prob),\n",
        "            \"best_arch\": best_arch.copy(),\n",
        "            \"best_loss\": float(best_loss),\n",
        "        })\n",
        "\n",
        "        if verbose:\n",
        "            status = \"ACCEPT ‚úÖ\" if accepted else \"reject ‚ùå\"\n",
        "            print(\n",
        "                f\"[{t+1:03d}] {status} | \"\n",
        "                f\"prop={proposed_arch} loss={proposed_loss:.6f} | \"\n",
        "                f\"cur={current_arch} loss={current_loss:.6f} | \"\n",
        "                f\"best={best_arch} best_loss={best_loss:.6f} | \"\n",
        "                f\"p={accept_prob:.3f}\"\n",
        "            )\n",
        "\n",
        "    return {\n",
        "        \"best_arch\": best_arch,\n",
        "        \"best_loss\": best_loss,\n",
        "        \"history\": history,\n",
        "        \"loss_cache_size\": len(loss_cache),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "rE4ugeWEKI6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "def sanity_checks():\n",
        "    print(\"=== 1) –ü—Ä–æ–≤–µ—Ä–∫–∞ MLP: —Ñ–æ—Ä–º—ã –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞ ===\")\n",
        "    model = MLP(input_dim=10, output_dim=3, arch=[32, 16], activation=\"relu\", dropout=0.1).to(device)\n",
        "    x = torch.randn(5, 10).to(device)\n",
        "    yhat = model(x)\n",
        "    print(\"model(x).shape =\", tuple(yhat.shape))\n",
        "    assert yhat.shape == (5, 3), \"‚ùå –ù–µ–≤–µ—Ä–Ω–∞—è —Ñ–æ—Ä–º–∞ –≤—ã—Ö–æ–¥–∞ MLP\"\n",
        "    print(\"‚úÖ MLP —Ñ–æ—Ä–º—ã –æ–∫\\n\")\n",
        "\n",
        "    print(\"=== 2) –ü—Ä–æ–≤–µ—Ä–∫–∞ propose_architecture: –æ–¥–∏–Ω —Å–ª–æ–π –º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ ¬±step –∏ –≤ –≥—Ä–∞–Ω–∏—Ü–∞—Ö ===\")\n",
        "    arch0 = [32, 32, 32]\n",
        "    min_u, max_u, step = 8, 128, 8\n",
        "\n",
        "    for _ in range(200):\n",
        "        arch1 = propose_architecture(arch0, min_units=min_u, max_units=max_u, step=step)\n",
        "        assert len(arch1) == len(arch0), \"‚ùå –î–ª–∏–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏–∑–º–µ–Ω–∏–ª–∞—Å—å\"\n",
        "        assert all(min_u <= a <= max_u for a in arch1), \"‚ùå –í—ã—à–ª–∏ –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã min/max\"\n",
        "\n",
        "        # –ü—Ä–æ–≤–µ—Ä–∫–∞: –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –º–∞–∫—Å–∏–º—É–º –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç, –∏ –æ—Ç–ª–∏—á–∏–µ –ª–∏–±–æ 0, –ª–∏–±–æ —Ä–æ–≤–Ω–æ step\n",
        "        diffs = [abs(a - b) for a, b in zip(arch0, arch1)]\n",
        "        nonzero = [d for d in diffs if d != 0]\n",
        "        assert len(nonzero) in [0, 1], \"‚ùå –ú–µ–Ω—è–µ—Ç—Å—è –±–æ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ —Å–ª–æ—è –∑–∞ —à–∞–≥\"\n",
        "        if len(nonzero) == 1:\n",
        "            assert nonzero[0] == step, \"‚ùå –®–∞–≥ –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ —Ä–∞–≤–µ–Ω step\"\n",
        "    print(\"‚úÖ propose_architecture –æ–∫\\n\")\n",
        "\n",
        "    print(\"=== 3) –ì–æ—Ç–æ–≤–∏–º –º–∞–ª–µ–Ω—å–∫–∏–π —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (–±—ã—Å—Ç—Ä–æ) ===\")\n",
        "    # y = Xw + —à—É–º (–ø—Ä–æ—Å—Ç–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è, —á—Ç–æ–±—ã –æ–±—É—á–µ–Ω–∏–µ –±—ã–ª–æ —Å—Ç–∞–±–∏–ª—å–Ω—ã–º)\n",
        "    torch.manual_seed(0)\n",
        "    N = 1200\n",
        "    input_dim = 10\n",
        "    output_dim = 1\n",
        "\n",
        "    X = torch.randn(N, input_dim)\n",
        "    true_w = torch.randn(input_dim, output_dim)\n",
        "    y = X @ true_w + 0.1 * torch.randn(N, output_dim)\n",
        "\n",
        "    # train/val split\n",
        "    n_train = 900\n",
        "    X_train, y_train = X[:n_train], y[:n_train]\n",
        "    X_val, y_val     = X[n_train:], y[n_train:]\n",
        "\n",
        "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=128, shuffle=True)\n",
        "    val_loader   = DataLoader(TensorDataset(X_val, y_val), batch_size=256, shuffle=False)\n",
        "\n",
        "    print(\"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –≥–æ—Ç–æ–≤\\n\")\n",
        "\n",
        "    print(\"=== 4) –ü—Ä–æ–≤–µ—Ä–∫–∞ train_and_get_val_loss: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω–µ—á–Ω–æ–µ —á–∏—Å–ª–æ ===\")\n",
        "    loss1 = train_and_get_val_loss(\n",
        "        arch=[32, 16, 8],\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        input_dim=input_dim,\n",
        "        output_dim=output_dim,\n",
        "        task=\"regression\",\n",
        "        activation=\"relu\",\n",
        "        lr=1e-3,\n",
        "        epochs=3,\n",
        "        dropout=0.0,\n",
        "        weight_decay=0.0,\n",
        "        verbose=False\n",
        "    )\n",
        "    print(\"val_loss =\", loss1)\n",
        "    assert isinstance(loss1, float), \"‚ùå val_loss –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å float\"\n",
        "    assert np.isfinite(loss1), \"‚ùå val_loss nan/inf\"\n",
        "    print(\"‚úÖ train_and_get_val_loss –æ–∫\\n\")\n",
        "\n",
        "    print(\"=== 5) –ü—Ä–æ–≤–µ—Ä–∫–∞ MCMC (Metropolis-Hastings): —à–∞–≥–∏, accept/reject, –∏—Å—Ç–æ—Ä–∏—è ===\")\n",
        "    cfg = MCMCConfig(\n",
        "        K=3,\n",
        "        min_units=8,\n",
        "        max_units=128,\n",
        "        step=8,\n",
        "        iters=12,            # –º–∞–ª–æ, —á—Ç–æ–±—ã –±—ã—Å—Ç—Ä–æ\n",
        "        temperature=0.005,    # –º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å\n",
        "        train_epochs=3,      # –º–∞–ª–æ, —á—Ç–æ–±—ã –±—ã—Å—Ç—Ä–æ\n",
        "        lr=1e-3,\n",
        "        activation=\"relu\",\n",
        "        dropout=0.0,\n",
        "        weight_decay=0.0,\n",
        "        task=\"regression\",\n",
        "        cache=True\n",
        "    )\n",
        "\n",
        "    res = metropolis_hastings_arch_search(\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        input_dim=input_dim,\n",
        "        output_dim=output_dim,\n",
        "        init_arch=[32, 32, 32],\n",
        "        cfg=cfg,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    assert \"best_arch\" in res and \"best_loss\" in res and \"history\" in res, \"‚ùå –ù–µ–ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç MCMC\"\n",
        "    assert len(res[\"history\"]) == cfg.iters, \"‚ùå –î–ª–∏–Ω–∞ history –Ω–µ —Ä–∞–≤–Ω–∞ iters\"\n",
        "    assert np.isfinite(res[\"best_loss\"]), \"‚ùå best_loss nan/inf\"\n",
        "\n",
        "    accepts = [h[\"accepted\"] for h in res[\"history\"]]\n",
        "    acc_rate = sum(accepts) / len(accepts)\n",
        "    print(\"acceptance rate =\", acc_rate)\n",
        "    print(\"best_arch =\", res[\"best_arch\"])\n",
        "    print(\"best_loss =\", res[\"best_loss\"])\n",
        "\n",
        "    # best_loss –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–∏–Ω–∏–º—É–º–æ–º –ø–æ best_loss –≤ –∏—Å—Ç–æ—Ä–∏–∏\n",
        "    best_losses = [h[\"best_loss\"] for h in res[\"history\"]]\n",
        "    assert abs(res[\"best_loss\"] - min(best_losses)) < 1e-12, \"‚ùå best_loss –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –º–∏–Ω–∏–º—É–º–æ–º –ø–æ –∏—Å—Ç–æ—Ä–∏–∏\"\n",
        "\n",
        "    # sanity: accept_prob –≤ [0,1]\n",
        "    assert all(0.0 <= h[\"accept_prob\"] <= 1.0 for h in res[\"history\"]), \"‚ùå accept_prob –≤–Ω–µ [0,1]\"\n",
        "\n",
        "    print(\"‚úÖ MCMC –æ–∫\\n\")\n",
        "\n",
        "    print(\"üéâ –í–°–Å –ü–†–û–®–õ–û: –±–∞–∑–æ–≤–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø—É–Ω–∫—Ç–∞ (b) —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.\")\n",
        "\n",
        "sanity_checks()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23mzISsaVVyk",
        "outputId": "b3eca28f-f15a-4047-a054-6cbe12c49153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 1) –ü—Ä–æ–≤–µ—Ä–∫–∞ MLP: —Ñ–æ—Ä–º—ã –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞ ===\n",
            "model(x).shape = (5, 3)\n",
            "‚úÖ MLP —Ñ–æ—Ä–º—ã –æ–∫\n",
            "\n",
            "=== 2) –ü—Ä–æ–≤–µ—Ä–∫–∞ propose_architecture: –æ–¥–∏–Ω —Å–ª–æ–π –º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ ¬±step –∏ –≤ –≥—Ä–∞–Ω–∏—Ü–∞—Ö ===\n",
            "‚úÖ propose_architecture –æ–∫\n",
            "\n",
            "=== 3) –ì–æ—Ç–æ–≤–∏–º –º–∞–ª–µ–Ω—å–∫–∏–π —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (–±—ã—Å—Ç—Ä–æ) ===\n",
            "‚úÖ –î–∞—Ç–∞—Å–µ—Ç –≥–æ—Ç–æ–≤\n",
            "\n",
            "=== 4) –ü—Ä–æ–≤–µ—Ä–∫–∞ train_and_get_val_loss: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω–µ—á–Ω–æ–µ —á–∏—Å–ª–æ ===\n",
            "val_loss = 17.18493570963542\n",
            "‚úÖ train_and_get_val_loss –æ–∫\n",
            "\n",
            "=== 5) –ü—Ä–æ–≤–µ—Ä–∫–∞ MCMC (Metropolis-Hastings): —à–∞–≥–∏, accept/reject, –∏—Å—Ç–æ—Ä–∏—è ===\n",
            "acceptance rate = 0.3333333333333333\n",
            "best_arch = [40, 40, 32]\n",
            "best_loss = 16.006267598470053\n",
            "‚úÖ MCMC –æ–∫\n",
            "\n",
            "üéâ –í–°–Å –ü–†–û–®–õ–û: –±–∞–∑–æ–≤–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø—É–Ω–∫—Ç–∞ (b) —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **–ü—É–Ω–∫—Ç C**"
      ],
      "metadata": {
        "id": "kZ8V_khmdCVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, math, random\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime, timedelta, date\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import importlib, subprocess, sys\n",
        "\n",
        "def ensure_pkg(pkg: str):\n",
        "    try:\n",
        "        importlib.import_module(pkg)\n",
        "    except ImportError:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "ensure_pkg(\"xlrd\")\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdRrwLNokjaq",
        "outputId": "badc6668-88ba-4466-cf9c-b4d4d871cd3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim: int, output_dim: int, arch: List[int],\n",
        "                 activation: str = \"relu\", dropout: float = 0.0):\n",
        "        super().__init__()\n",
        "        act_layer = {\n",
        "            \"relu\": nn.ReLU,\n",
        "            \"tanh\": nn.Tanh,\n",
        "            \"gelu\": nn.GELU,\n",
        "            \"sigmoid\": nn.Sigmoid,\n",
        "        }.get(activation.lower(), nn.ReLU)\n",
        "\n",
        "        layers = []\n",
        "        prev = input_dim\n",
        "        for w in arch:\n",
        "            layers.append(nn.Linear(prev, w))\n",
        "            layers.append(act_layer())\n",
        "            if dropout and dropout > 0:\n",
        "                layers.append(nn.Dropout(dropout))\n",
        "            prev = w\n",
        "        layers.append(nn.Linear(prev, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_loss(model: nn.Module, loader: DataLoader, loss_fn) -> float:\n",
        "    model.eval()\n",
        "    total, n = 0.0, 0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        pred = model(xb)\n",
        "        loss = loss_fn(pred, yb)\n",
        "        total += loss.item() * xb.size(0)\n",
        "        n += xb.size(0)\n",
        "    return total / max(n, 1)\n",
        "\n",
        "\n",
        "def train_and_get_val_loss(\n",
        "    arch: List[int],\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    input_dim: int,\n",
        "    output_dim: int,\n",
        "    lr: float = 1e-3,\n",
        "    epochs: int = 10,\n",
        "    weight_decay: float = 0.0,\n",
        "    dropout: float = 0.0,\n",
        "    activation: str = \"relu\",\n",
        "    seed_for_arch: Optional[int] = None,\n",
        ") -> float:\n",
        "\n",
        "    if seed_for_arch is not None:\n",
        "        set_seed(seed_for_arch)\n",
        "\n",
        "    model = MLP(input_dim, output_dim, arch, activation=activation, dropout=dropout).to(device)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "    return float(evaluate_loss(model, val_loader, loss_fn))\n",
        "\n",
        "\n",
        "def propose_architecture(arch: List[int], min_units: int, max_units: int, step: int = 8) -> List[int]:\n",
        "    new_arch = arch.copy()\n",
        "    i = random.randrange(len(new_arch))\n",
        "    direction = random.choice([-1, +1])\n",
        "    cand = new_arch[i] + direction * step\n",
        "    if cand < min_units or cand > max_units:\n",
        "        return new_arch\n",
        "    new_arch[i] = int(cand)\n",
        "    return new_arch\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MCMCConfig:\n",
        "    K: int = 3\n",
        "    min_units: int = 8\n",
        "    max_units: int = 128\n",
        "    step: int = 8\n",
        "    iters: int = 30\n",
        "    temperature: float = 0.005\n",
        "\n",
        "    train_epochs: int = 10\n",
        "    lr: float = 1e-3\n",
        "    weight_decay: float = 1e-4\n",
        "    dropout: float = 0.1\n",
        "    activation: str = \"relu\"\n",
        "\n",
        "    cache: bool = True\n",
        "    seed_base: int = 12345\n",
        "\n",
        "\n",
        "def metropolis_hastings_arch_search(\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    input_dim: int,\n",
        "    output_dim: int,\n",
        "    init_arch: List[int],\n",
        "    cfg: MCMCConfig,\n",
        "    verbose: bool = True\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    assert len(init_arch) == cfg.K, \"init_arch –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –¥–ª–∏–Ω—É K\"\n",
        "\n",
        "    loss_cache: Dict[Tuple[int, ...], float] = {}\n",
        "\n",
        "    def get_loss(a: List[int]) -> float:\n",
        "        key = tuple(a)\n",
        "        if cfg.cache and key in loss_cache:\n",
        "            return loss_cache[key]\n",
        "\n",
        "\n",
        "        seed_for_arch = cfg.seed_base + (abs(hash(key)) % 100000)\n",
        "\n",
        "        val_loss = train_and_get_val_loss(\n",
        "            arch=a,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            input_dim=input_dim,\n",
        "            output_dim=output_dim,\n",
        "            lr=cfg.lr,\n",
        "            epochs=cfg.train_epochs,\n",
        "            weight_decay=cfg.weight_decay,\n",
        "            dropout=cfg.dropout,\n",
        "            activation=cfg.activation,\n",
        "            seed_for_arch=seed_for_arch\n",
        "        )\n",
        "\n",
        "        if cfg.cache:\n",
        "            loss_cache[key] = val_loss\n",
        "        return val_loss\n",
        "\n",
        "    cur_arch = init_arch.copy()\n",
        "    cur_loss = get_loss(cur_arch)\n",
        "\n",
        "    best_arch = cur_arch.copy()\n",
        "    best_loss = cur_loss\n",
        "\n",
        "    history = []\n",
        "    if verbose:\n",
        "        print(f\"Start: arch={cur_arch}, val_loss={cur_loss:.6f}\")\n",
        "\n",
        "    for t in range(cfg.iters):\n",
        "        prop_arch = propose_architecture(cur_arch, cfg.min_units, cfg.max_units, cfg.step)\n",
        "        prop_loss = get_loss(prop_arch)\n",
        "\n",
        "        delta = prop_loss - cur_loss\n",
        "        if delta <= 0:\n",
        "            acc_prob = 1.0\n",
        "        else:\n",
        "            acc_prob = math.exp(-delta / max(cfg.temperature, 1e-12))\n",
        "\n",
        "        accepted = (random.random() < acc_prob)\n",
        "        if accepted:\n",
        "            cur_arch, cur_loss = prop_arch, prop_loss\n",
        "\n",
        "        if cur_loss < best_loss:\n",
        "            best_arch, best_loss = cur_arch.copy(), cur_loss\n",
        "\n",
        "        history.append({\n",
        "            \"iter\": t+1,\n",
        "            \"cur_arch\": cur_arch.copy(),\n",
        "            \"cur_loss\": float(cur_loss),\n",
        "            \"prop_arch\": prop_arch.copy(),\n",
        "            \"prop_loss\": float(prop_loss),\n",
        "            \"acc_prob\": float(acc_prob),\n",
        "            \"accepted\": bool(accepted),\n",
        "            \"best_arch\": best_arch.copy(),\n",
        "            \"best_loss\": float(best_loss),\n",
        "        })\n",
        "\n",
        "        if verbose:\n",
        "            tag = \"ACCEPT ‚úÖ\" if accepted else \"reject ‚ùå\"\n",
        "            print(f\"[{t+1:03d}] {tag} | prop={prop_arch} {prop_loss:.6f} | cur={cur_arch} {cur_loss:.6f} | best={best_arch} {best_loss:.6f} | p={acc_prob:.3f}\")\n",
        "\n",
        "    return {\n",
        "        \"best_arch\": best_arch,\n",
        "        \"best_loss\": best_loss,\n",
        "        \"history\": history,\n",
        "        \"loss_cache_size\": len(loss_cache),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Pwx5mEExkm5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "rp5_path = next(iter(uploaded.keys()))\n",
        "print(\"Uploaded:\", rp5_path)\n",
        "\n",
        "\n",
        "def _norm_cell(x) -> str:\n",
        "    if pd.isna(x):\n",
        "        return \"\"\n",
        "    s = str(x)\n",
        "    s = s.replace(\"\\xa0\", \" \").replace(\"\\n\", \" \")\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "\n",
        "def read_rp5_any(path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    1) –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ –Ω–∞—Å—Ç–æ—è—â–∏–π Excel .xls\n",
        "    2) –ï—Å–ª–∏ –≤–¥—Ä—É–≥ —ç—Ç–æ 'xls –∫–∞–∫ HTML' ‚Äî –ø—Ä–æ–±—É–µ–º read_html\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df0 = pd.read_excel(path, header=None)\n",
        "        print(\"Loaded as Excel (.xls). shape:\", df0.shape)\n",
        "        return df0\n",
        "    except Exception as e_excel:\n",
        "        try:\n",
        "            df0 = pd.read_html(path, header=None)[0]\n",
        "            print(\"Loaded as HTML-table disguised as xls. shape:\", df0.shape)\n",
        "            return df0\n",
        "        except Exception as e_html:\n",
        "            raise RuntimeError(\n",
        "                \"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –Ω–∏ –∫–∞–∫ Excel, –Ω–∏ –∫–∞–∫ HTML.\\n\"\n",
        "                f\"Excel error: {repr(e_excel)}\\n\"\n",
        "                f\"HTML error: {repr(e_html)}\"\n",
        "            )\n",
        "\n",
        "\n",
        "def build_table_from_rp5(df0: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    rp5 –≤—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.\n",
        "    –ú—ã –∏—â–µ–º —Å—Ç—Ä–æ–∫—É, –≥–¥–µ –≤ –ø–µ—Ä–≤–æ–º —Å—Ç–æ–ª–±—Ü–µ –µ—Å—Ç—å '–ú–µ—Å—Ç–Ω–æ–µ –≤—Ä–µ–º—è' (—Å –≤–∞—Ä–∏–∞—Ü–∏—è–º–∏),\n",
        "    –±–µ—Ä—ë–º –µ—ë –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –≤—Å—ë –Ω–∏–∂–µ ‚Äî –∫–∞–∫ –¥–∞–Ω–Ω—ã–µ.\n",
        "    \"\"\"\n",
        "    header_row = None\n",
        "\n",
        "    # 1) –∏—â–µ–º –ø–æ –ø–µ—Ä–≤–æ–º—É —Å—Ç–æ–ª–±—Ü—É (—Å–∞–º—ã–π –Ω–∞–¥—ë–∂–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫)\n",
        "    for i in range(len(df0)):\n",
        "        first = _norm_cell(df0.iloc[i, 0]).lower()\n",
        "        if (\"–º–µ—Å—Ç–Ω–æ–µ\" in first) and (\"–≤—Ä–µ–º—è\" in first):\n",
        "            header_row = i\n",
        "            break\n",
        "\n",
        "    # 2) –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç: –µ—Å–ª–∏ –≤–¥—Ä—É–≥ \"–ú–µ—Å—Ç–Ω–æ–µ –≤—Ä–µ–º—è\" –Ω–µ —Å—Ç—Ä–æ–≥–æ –≤ –ø–µ—Ä–≤–æ–º —Å—Ç–æ–ª–±—Ü–µ\n",
        "    if header_row is None:\n",
        "        for i in range(min(len(df0), 500)):\n",
        "            row = \" \".join(_norm_cell(v).lower() for v in df0.iloc[i].tolist())\n",
        "            if (\"–º–µ—Å—Ç–Ω–æ–µ\" in row) and (\"–≤—Ä–µ–º—è\" in row):\n",
        "                header_row = i\n",
        "                break\n",
        "\n",
        "    if header_row is None:\n",
        "        # –ß—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ \"–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç\": –≤—ã–≤–µ–¥–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏\n",
        "        preview = df0.iloc[:12, :8].copy()\n",
        "        preview = preview.applymap(_norm_cell)\n",
        "        raise RuntimeError(\"–ù–µ –Ω–∞—à—ë–ª —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —Å '–ú–µ—Å—Ç–Ω–æ–µ –≤—Ä–µ–º—è'. –í–æ—Ç –ø–µ—Ä–≤—ã–µ 12 —Å—Ç—Ä–æ–∫ (8 –∫–æ–ª–æ–Ω–æ–∫):\\n\" + str(preview))\n",
        "\n",
        "    headers = [_norm_cell(v) for v in df0.iloc[header_row].tolist()]\n",
        "    # –∑–∞–ø–æ–ª–Ω—è–µ–º –ø—É—Å—Ç—ã–µ –∏–º–µ–Ω–∞\n",
        "    headers = [h if h not in (\"\", \"nan\", \"None\") else f\"col_{j}\" for j, h in enumerate(headers)]\n",
        "\n",
        "    # –¥–µ–ª–∞–µ–º –∏–º–µ–Ω–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏\n",
        "    seen = {}\n",
        "    uniq = []\n",
        "    for h in headers:\n",
        "        k = seen.get(h, 0)\n",
        "        uniq.append(h if k == 0 else f\"{h}_{k}\")\n",
        "        seen[h] = k + 1\n",
        "\n",
        "    data = df0.iloc[header_row + 1:].copy()\n",
        "    data.columns = uniq\n",
        "    data = data.dropna(how=\"all\").reset_index(drop=True)\n",
        "\n",
        "    print(\"Header row index:\", header_row)\n",
        "    print(\"Columns (first 20):\", list(data.columns)[:20])\n",
        "    return data\n",
        "\n",
        "\n",
        "df0 = read_rp5_any(rp5_path)\n",
        "df_raw = build_table_from_rp5(df0)\n",
        "\n",
        "df_raw.head(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "bv-JQE-3ksPG",
        "outputId": "1e7a93a8-0a8f-4bc8-8d85-17adc49ba825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0b86ef23-b41b-43f4-8615-aa05993a3386\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0b86ef23-b41b-43f4-8615-aa05993a3386\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 27612.23.12.2020.22.12.2025.1.0.0.ru.utf8.00000000.xls to 27612.23.12.2020.22.12.2025.1.0.0.ru.utf8.00000000 (1).xls\n",
            "Uploaded: 27612.23.12.2020.22.12.2025.1.0.0.ru.utf8.00000000 (1).xls\n",
            "Loaded as Excel (.xls). shape: (14609, 29)\n",
            "Header row index: 6\n",
            "Columns (first 20): ['–ú–µ—Å—Ç–Ω–æ–µ –≤—Ä–µ–º—è –≤ –ú–æ—Å–∫–≤–µ (–í–î–ù–•)', 'T', 'Po', 'P', 'Pa', 'U', 'DD', 'Ff', 'ff10', 'ff3', 'N', 'WW', 'W1', 'W2', 'Tn', 'Tx', 'Cl', 'Nh', 'H', 'Cm']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  –ú–µ—Å—Ç–Ω–æ–µ –≤—Ä–µ–º—è –≤ –ú–æ—Å–∫–≤–µ (–í–î–ù–•)    T     Po      P   Pa   U  \\\n",
              "0              22.12.2025 21:00 -4.3  746.6  760.9  1.6  62   \n",
              "1              22.12.2025 18:00 -2.3    745  759.1  2.3  81   \n",
              "2              22.12.2025 15:00    0  742.7  756.7  1.6  87   \n",
              "3              22.12.2025 12:00  1.8  741.1  754.9  0.6  93   \n",
              "4              22.12.2025 09:00  1.5  740.5  754.4  0.3  96   \n",
              "\n",
              "                                     DD Ff ff10  ff3  ...  \\\n",
              "0  –í–µ—Ç–µ—Ä, –¥—É—é—â–∏–π —Å —Å–µ–≤–µ—Ä–æ-—Å–µ–≤–µ—Ä–æ-–∑–∞–ø–∞–¥–∞  4  NaN   10  ...   \n",
              "1         –í–µ—Ç–µ—Ä, –¥—É—é—â–∏–π —Å —Å–µ–≤–µ—Ä–æ-–∑–∞–ø–∞–¥–∞  3  NaN   10  ...   \n",
              "2         –í–µ—Ç–µ—Ä, –¥—É—é—â–∏–π —Å —Å–µ–≤–µ—Ä–æ-–∑–∞–ø–∞–¥–∞  3  NaN   10  ...   \n",
              "3         –í–µ—Ç–µ—Ä, –¥—É—é—â–∏–π —Å —Å–µ–≤–µ—Ä–æ-–∑–∞–ø–∞–¥–∞  2  NaN  NaN  ...   \n",
              "4                –í–µ—Ç–µ—Ä, –¥—É—é—â–∏–π —Å –∑–∞–ø–∞–¥–∞  1  NaN  NaN  ...   \n",
              "\n",
              "                                                  Cm  \\\n",
              "0  –í—ã—Å–æ–∫–æ–∫—É—á–µ–≤—ã—Ö, –≤—ã—Å–æ–∫–æ—Å–ª–æ–∏—Å—Ç—ã—Ö –∏–ª–∏ —Å–ª–æ–∏—Å—Ç–æ-–¥–æ–∂–¥...   \n",
              "1  –í—ã—Å–æ–∫–æ–∫—É—á–µ–≤—ã—Ö, –≤—ã—Å–æ–∫–æ—Å–ª–æ–∏—Å—Ç—ã—Ö –∏–ª–∏ —Å–ª–æ–∏—Å—Ç–æ-–¥–æ–∂–¥...   \n",
              "2                                                NaN   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "\n",
              "                                                  Ch  VV    Td  RRR   tR    E  \\\n",
              "0  –ü–µ—Ä–∏—Å—Ç—ã—Ö, –ø–µ—Ä–∏—Å—Ç–æ-–∫—É—á–µ–≤—ã—Ö –∏–ª–∏ –ø–µ—Ä–∏—Å—Ç–æ-—Å–ª–æ–∏—Å—Ç—ã—Ö...  20 -10.6  0.2   12  NaN   \n",
              "1  –ü–µ—Ä–∏—Å—Ç—ã—Ö, –ø–µ—Ä–∏—Å—Ç–æ-–∫—É—á–µ–≤—ã—Ö –∏–ª–∏ –ø–µ—Ä–∏—Å—Ç–æ-—Å–ª–æ–∏—Å—Ç—ã—Ö...  20  -5.1  0.4   12  NaN   \n",
              "2                                                NaN   9  -1.9  NaN  NaN  NaN   \n",
              "3                                                NaN  20   0.7  NaN  NaN  NaN   \n",
              "4                                                NaN  18   0.9    1   12  NaN   \n",
              "\n",
              "    Tg   E'  sss  \n",
              "0  NaN  NaN  NaN  \n",
              "1  NaN  NaN  NaN  \n",
              "2  NaN  NaN  NaN  \n",
              "3  NaN  NaN  NaN  \n",
              "4  NaN  NaN  NaN  \n",
              "\n",
              "[5 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34debc96-d1c7-4fcc-85dd-c2c6357d4281\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>–ú–µ—Å—Ç–Ω–æ–µ –≤—Ä–µ–º—è –≤ –ú–æ—Å–∫–≤–µ (–í–î–ù–•)</th>\n",
              "      <th>T</th>\n",
              "      <th>Po</th>\n",
              "      <th>P</th>\n",
              "      <th>Pa</th>\n",
              "      <th>U</th>\n",
              "      <th>DD</th>\n",
              "      <th>Ff</th>\n",
              "      <th>ff10</th>\n",
              "      <th>ff3</th>\n",
              "      <th>...</th>\n",
              "      <th>Cm</th>\n",
              "      <th>Ch</th>\n",
              "      <th>VV</th>\n",
              "      <th>Td</th>\n",
              "      <th>RRR</th>\n",
              "      <th>tR</th>\n",
              "      <th>E</th>\n",
              "      <th>Tg</th>\n",
              "      <th>E'</th>\n",
              "      <th>sss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.12.2025 21:00</td>\n",
              "      <td>-4.3</td>\n",
              "      <td>746.6</td>\n",
              "      <td>760.9</td>\n",
              "      <td>1.6</td>\n",
              "      <td>62</td>\n",
              "      <td>–í–µ—Ç–µ—Ä, –¥—É—é—â–∏–π —Å —Å–µ–≤–µ—Ä–æ-—Å–µ–≤–µ—Ä–æ-–∑–∞–ø–∞–¥–∞</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>–í—ã—Å–æ–∫–æ–∫—É—á–µ–≤—ã—Ö, –≤—ã—Å–æ–∫–æ—Å–ª–æ–∏—Å—Ç—ã—Ö –∏–ª–∏ —Å–ª–æ–∏—Å—Ç–æ-–¥–æ–∂–¥...</td>\n",
              "      <td>–ü–µ—Ä–∏—Å—Ç—ã—Ö, –ø–µ—Ä–∏—Å—Ç–æ-–∫—É—á–µ–≤—ã—Ö –∏–ª–∏ –ø–µ—Ä–∏—Å—Ç–æ-—Å–ª–æ–∏—Å—Ç—ã—Ö...</td>\n",
              "      <td>20</td>\n",
              "      <td>-10.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22.12.2025 18:00</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>745</td>\n",
              "      <td>759.1</td>\n",
              "      <td>2.3</td>\n",
              "      <td>81</td>\n",
              "      <td>–í–µ—Ç–µ—Ä, –¥—É—é—â–∏–π —Å —Å–µ–≤–µ—Ä–æ-–∑–∞–ø–∞–¥–∞</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>–í—ã—Å–æ–∫–æ–∫—É—á–µ–≤—ã—Ö, –≤—ã—Å–æ–∫–æ—Å–ª–æ–∏—Å—Ç—ã—Ö –∏–ª–∏ —Å–ª–æ–∏—Å—Ç–æ-–¥–æ–∂–¥...</td>\n",
              "      <td>–ü–µ—Ä–∏—Å—Ç—ã—Ö, –ø–µ—Ä–∏—Å—Ç–æ-–∫—É—á–µ–≤—ã—Ö –∏–ª–∏ –ø–µ—Ä–∏—Å—Ç–æ-—Å–ª–æ–∏—Å—Ç—ã—Ö...</td>\n",
              "      <td>20</td>\n",
              "      <td>-5.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22.12.2025 15:00</td>\n",
              "      <td>0</td>\n",
              "      <td>742.7</td>\n",
              "      <td>756.7</td>\n",
              "      <td>1.6</td>\n",
              "      <td>87</td>\n",
              "      <td>–í–µ—Ç–µ—Ä, –¥—É—é—â–∏–π —Å —Å–µ–≤–µ—Ä–æ-–∑–∞–ø–∞–¥–∞</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22.12.2025 12:00</td>\n",
              "      <td>1.8</td>\n",
              "      <td>741.1</td>\n",
              "      <td>754.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>93</td>\n",
              "      <td>–í–µ—Ç–µ—Ä, –¥—É—é—â–∏–π —Å —Å–µ–≤–µ—Ä–æ-–∑–∞–ø–∞–¥–∞</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20</td>\n",
              "      <td>0.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22.12.2025 09:00</td>\n",
              "      <td>1.5</td>\n",
              "      <td>740.5</td>\n",
              "      <td>754.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>96</td>\n",
              "      <td>–í–µ—Ç–µ—Ä, –¥—É—é—â–∏–π —Å –∑–∞–ø–∞–¥–∞</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34debc96-d1c7-4fcc-85dd-c2c6357d4281')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-34debc96-d1c7-4fcc-85dd-c2c6357d4281 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-34debc96-d1c7-4fcc-85dd-c2c6357d4281');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a8d954ce-b539-405a-b7a0-1dd8b1952a23\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8d954ce-b539-405a-b7a0-1dd8b1952a23')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a8d954ce-b539-405a-b7a0-1dd8b1952a23 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_raw"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pick_col(df: pd.DataFrame, names: List[str]) -> str:\n",
        "    # —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ\n",
        "    for n in names:\n",
        "        if n in df.columns:\n",
        "            return n\n",
        "    # –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ\n",
        "    norm_map = {re.sub(r\"\\s+\", \" \", str(c)).strip().lower(): c for c in df.columns}\n",
        "    for n in names:\n",
        "        key = n.strip().lower()\n",
        "        if key in norm_map:\n",
        "            return norm_map[key]\n",
        "    # —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ\n",
        "    for n in names:\n",
        "        for c in df.columns:\n",
        "            if n.lower() in str(c).lower():\n",
        "                return c\n",
        "    raise KeyError(f\"–ù–µ –Ω–∞—à—ë–ª –∫–æ–ª–æ–Ω–∫—É —Å—Ä–µ–¥–∏ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {names}\\n–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)[:40]} ...\")\n",
        "\n",
        "\n",
        "dt_col = pick_col(df_raw, [\"–ú–µ—Å—Ç–Ω–æ–µ –≤—Ä–µ–º—è\", \"Local time\", \"Time\"])\n",
        "T_col  = pick_col(df_raw, [\"T\"])\n",
        "U_col  = pick_col(df_raw, [\"U\"])\n",
        "Ff_col = pick_col(df_raw, [\"Ff\", \"FF\", \"ff\"])\n",
        "\n",
        "print(\"Using columns:\", {\"dt\": dt_col, \"T\": T_col, \"U\": U_col, \"Ff\": Ff_col})\n",
        "\n",
        "\n",
        "def to_float(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    s = _norm_cell(x).replace(\",\", \".\")\n",
        "    m = re.search(r\"-?\\d+(\\.\\d+)?\", s)\n",
        "    return float(m.group(0)) if m else np.nan\n",
        "\n",
        "\n",
        "df = df_raw[[dt_col, T_col, U_col, Ff_col]].copy()\n",
        "df.columns = [\"dt\", \"T\", \"U\", \"Ff\"]\n",
        "\n",
        "df[\"dt\"] = pd.to_datetime(df[\"dt\"], errors=\"coerce\", dayfirst=True)\n",
        "for c in [\"T\", \"U\", \"Ff\"]:\n",
        "    df[c] = df[c].apply(to_float)\n",
        "\n",
        "df = df.dropna(subset=[\"dt\"]).sort_values(\"dt\").reset_index(drop=True)\n",
        "\n",
        "print(\"Clean df shape:\", df.shape)\n",
        "print(\"Date range:\", df[\"dt\"].min(), \"‚Üí\", df[\"dt\"].max())\n",
        "df.head(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "auFQ5tB3lAd6",
        "outputId": "e8157fd6-ef98-415b-fbe1-76914b037cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using columns: {'dt': '–ú–µ—Å—Ç–Ω–æ–µ –≤—Ä–µ–º—è –≤ –ú–æ—Å–∫–≤–µ (–í–î–ù–•)', 'T': 'T', 'U': 'U', 'Ff': 'Ff'}\n",
            "Clean df shape: (14602, 4)\n",
            "Date range: 2020-12-23 00:00:00 ‚Üí 2025-12-22 21:00:00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   dt    T     U   Ff\n",
              "0 2020-12-23 00:00:00 -2.5  84.0  1.0\n",
              "1 2020-12-23 03:00:00 -2.5  88.0  1.0\n",
              "2 2020-12-23 06:00:00 -2.0  86.0  1.0\n",
              "3 2020-12-23 09:00:00 -2.7  82.0  1.0\n",
              "4 2020-12-23 12:00:00 -3.1  76.0  1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2237216-c6d4-49e9-bf03-f1c3f781fb7d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dt</th>\n",
              "      <th>T</th>\n",
              "      <th>U</th>\n",
              "      <th>Ff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-12-23 00:00:00</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>84.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-12-23 03:00:00</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-12-23 06:00:00</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-12-23 09:00:00</td>\n",
              "      <td>-2.7</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-12-23 12:00:00</td>\n",
              "      <td>-3.1</td>\n",
              "      <td>76.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2237216-c6d4-49e9-bf03-f1c3f781fb7d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2237216-c6d4-49e9-bf03-f1c3f781fb7d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2237216-c6d4-49e9-bf03-f1c3f781fb7d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ffef3a06-841b-4e9e-8786-9987d97fec2a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ffef3a06-841b-4e9e-8786-9987d97fec2a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ffef3a06-841b-4e9e-8786-9987d97fec2a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 14602,\n  \"fields\": [\n    {\n      \"column\": \"dt\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-12-23 00:00:00\",\n        \"max\": \"2025-12-22 21:00:00\",\n        \"num_unique_values\": 14602,\n        \"samples\": [\n          \"2021-01-13 03:00:00\",\n          \"2021-09-05 18:00:00\",\n          \"2022-01-04 06:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.630994949951889,\n        \"min\": -26.9,\n        \"max\": 34.6,\n        \"num_unique_values\": 575,\n        \"samples\": [\n          -2.8,\n          -23.4,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"U\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.550720065630173,\n        \"min\": 15.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 85,\n        \"samples\": [\n          22.0,\n          84.0,\n          29.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8591299613368741,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.0,\n          3.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ 15:00 (–æ–¥–Ω–∞ —Ç–æ—á–∫–∞ –Ω–∞ –¥–µ–Ω—å)\n",
        "df15 = df[df[\"dt\"].dt.hour == 15].copy()\n",
        "df15[\"date\"] = df15[\"dt\"].dt.date\n",
        "df15 = df15.drop_duplicates(subset=[\"date\"], keep=\"last\").sort_values(\"dt\").reset_index(drop=True)\n",
        "\n",
        "print(\"Rows at 15:00:\", len(df15))\n",
        "print(\"15:00 range:\", df15[\"dt\"].min(), \"‚Üí\", df15[\"dt\"].max())\n",
        "df15.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "mCQCDqqKlIri",
        "outputId": "a88dfb60-a2cd-4e4d-ab37-5baf2e554707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows at 15:00: 1825\n",
            "15:00 range: 2020-12-23 15:00:00 ‚Üí 2025-12-22 15:00:00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   dt    T     U   Ff        date\n",
              "0 2020-12-23 15:00:00 -3.7  78.0  3.0  2020-12-23\n",
              "1 2020-12-24 15:00:00 -3.9  84.0  1.0  2020-12-24\n",
              "2 2020-12-25 15:00:00 -4.8  90.0  4.0  2020-12-25\n",
              "3 2020-12-26 15:00:00  0.2  83.0  1.0  2020-12-26\n",
              "4 2020-12-27 15:00:00 -5.6  70.0  1.0  2020-12-27"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-293737fd-378e-4372-8e99-e067406d814a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dt</th>\n",
              "      <th>T</th>\n",
              "      <th>U</th>\n",
              "      <th>Ff</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-12-23 15:00:00</td>\n",
              "      <td>-3.7</td>\n",
              "      <td>78.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2020-12-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-12-24 15:00:00</td>\n",
              "      <td>-3.9</td>\n",
              "      <td>84.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2020-12-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-12-25 15:00:00</td>\n",
              "      <td>-4.8</td>\n",
              "      <td>90.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2020-12-25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-12-26 15:00:00</td>\n",
              "      <td>0.2</td>\n",
              "      <td>83.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2020-12-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-12-27 15:00:00</td>\n",
              "      <td>-5.6</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2020-12-27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-293737fd-378e-4372-8e99-e067406d814a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-293737fd-378e-4372-8e99-e067406d814a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-293737fd-378e-4372-8e99-e067406d814a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3b4c5747-129f-4f45-a114-efc289b9c423\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b4c5747-129f-4f45-a114-efc289b9c423')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3b4c5747-129f-4f45-a114-efc289b9c423 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df15",
              "summary": "{\n  \"name\": \"df15\",\n  \"rows\": 1825,\n  \"fields\": [\n    {\n      \"column\": \"dt\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-12-23 15:00:00\",\n        \"max\": \"2025-12-22 15:00:00\",\n        \"num_unique_values\": 1825,\n        \"samples\": [\n          \"2022-07-01 15:00:00\",\n          \"2025-10-03 15:00:00\",\n          \"2021-10-16 15:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.557042434402051,\n        \"min\": -22.8,\n        \"max\": 34.6,\n        \"num_unique_values\": 462,\n        \"samples\": [\n          7.1,\n          1.8,\n          -6.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"U\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.982084030819596,\n        \"min\": 15.0,\n        \"max\": 99.0,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          57.0,\n          78.0,\n          24.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7959469850310648,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.0,\n          1.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-12-23\",\n        \"max\": \"2025-12-22\",\n        \"num_unique_values\": 1825,\n        \"samples\": [\n          \"2022-07-01\",\n          \"2025-10-03\",\n          \"2021-10-16\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset_lookback(df15: pd.DataFrame, lookback_days: int = 7):\n",
        "    \"\"\"\n",
        "    X: –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π (15:00) –ø–æ [T, Ff, U]\n",
        "    y: —Å–ª–µ–¥—É—é—â–∏–π –¥–µ–Ω—å (15:00) [T, Ff, U]\n",
        "    –¢–æ–ª—å–∫–æ –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö –¥–Ω–µ–π (–±–µ–∑ –¥—ã—Ä).\n",
        "    \"\"\"\n",
        "    vals = df15[[\"T\", \"Ff\", \"U\"]].to_numpy(np.float32)\n",
        "    dates = df15[\"date\"].to_list()\n",
        "\n",
        "    X_list, y_list, y_dates = [], [], []\n",
        "    for i in range(lookback_days, len(df15)):\n",
        "        # –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ 7 –ø–æ–¥—Ä—è–¥ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö –¥–Ω–µ–π\n",
        "        ok = True\n",
        "        for j in range(i - lookback_days + 1, i + 1):\n",
        "            if (dates[j] - dates[j-1]).days != 1:\n",
        "                ok = False\n",
        "                break\n",
        "        if not ok:\n",
        "            continue\n",
        "\n",
        "        window = vals[i - lookback_days:i]   # (7,3)\n",
        "        target = vals[i]                     # (3,)\n",
        "        if np.any(np.isnan(window)) or np.any(np.isnan(target)):\n",
        "            continue\n",
        "\n",
        "        X_list.append(window.reshape(-1))    # (21,)\n",
        "        y_list.append(target)                # (3,)\n",
        "        y_dates.append(dates[i])\n",
        "\n",
        "    X = np.stack(X_list) if X_list else np.zeros((0, lookback_days*3), np.float32)\n",
        "    y = np.stack(y_list) if y_list else np.zeros((0, 3), np.float32)\n",
        "    return X, y, np.array(y_dates)\n",
        "\n",
        "X, y, y_dates = build_dataset_lookback(df15, lookback_days=7)\n",
        "print(\"Dataset shapes:\", X.shape, y.shape)\n",
        "print(\"First target date:\", y_dates[0] if len(y_dates) else None)\n",
        "print(\"Last target date:\", y_dates[-1] if len(y_dates) else None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWrTMZySlK1A",
        "outputId": "36fafbd0-5bd2-4d7d-b6b7-c095471cfcc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shapes: (1811, 21) (1811, 3)\n",
            "First target date: 2020-12-30\n",
            "Last target date: 2025-12-22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(X) > 200, \"–°–ª–∏—à–∫–æ–º –º–∞–ª–æ –ø—Ä–∏–º–µ—Ä–æ–≤. –ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ —Ñ–∏–ª—å—Ç—Ä 15:00 –∏ –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ—à–ª–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.\"\n",
        "\n",
        "n = len(X)\n",
        "n_train = int(n * 0.70)\n",
        "n_val   = int(n * 0.15)\n",
        "n_test  = n - n_train - n_val\n",
        "\n",
        "X_train, y_train = X[:n_train], y[:n_train]\n",
        "X_val,   y_val   = X[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
        "X_test,  y_test  = X[n_train+n_val:], y[n_train+n_val:]\n",
        "dates_test = y_dates[n_train+n_val:]\n",
        "\n",
        "print(\"Split sizes:\", {\"train\": len(X_train), \"val\": len(X_val), \"test\": len(X_test)})\n",
        "print(\"Test date range:\", dates_test[0], \"‚Üí\", dates_test[-1])\n",
        "\n",
        "x_mean = X_train.mean(axis=0, keepdims=True)\n",
        "x_std  = X_train.std(axis=0, keepdims=True) + 1e-8\n",
        "\n",
        "\n",
        "\n",
        "y_mean = y_train.mean(axis=0, keepdims=True)\n",
        "y_std  = y_train.std(axis=0, keepdims=True) + 1e-8\n",
        "\n",
        "print(y_std )\n",
        "\n",
        "def norm_X(a): return (a - x_mean) / x_std\n",
        "def norm_y(a): return (a - y_mean) / y_std\n",
        "def denorm_y(a): return a * y_std + y_mean\n",
        "\n",
        "X_train_n = norm_X(X_train).astype(np.float32)\n",
        "X_val_n   = norm_X(X_val).astype(np.float32)\n",
        "X_test_n  = norm_X(X_test).astype(np.float32)\n",
        "\n",
        "y_train_n = norm_y(y_train).astype(np.float32)\n",
        "y_val_n   = norm_y(y_val).astype(np.float32)\n",
        "y_test_n  = norm_y(y_test).astype(np.float32)\n",
        "\n",
        "def make_loader(Xn, yn, bs=256, shuffle=False):\n",
        "    Xt = torch.tensor(Xn, dtype=torch.float32)\n",
        "    yt = torch.tensor(yn, dtype=torch.float32)\n",
        "    return DataLoader(TensorDataset(Xt, yt), batch_size=bs, shuffle=shuffle)\n",
        "\n",
        "train_loader = make_loader(X_train_n, y_train_n, bs=128, shuffle=True)\n",
        "val_loader   = make_loader(X_val_n,   y_val_n,   bs=256, shuffle=False)\n",
        "test_loader  = make_loader(X_test_n,  y_test_n,  bs=256, shuffle=False)\n",
        "\n",
        "input_dim = X_train_n.shape[1]  # 21\n",
        "output_dim = y_train_n.shape[1] # 3\n",
        "print(\"input_dim:\", input_dim, \"output_dim:\", output_dim, \"(outputs: [T, Ff, U])\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXwugvkzlOtu",
        "outputId": "ffd235b7-8ca5-43f0-e315-6f0bc345f3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split sizes: {'train': 1267, 'val': 271, 'test': 273}\n",
            "Test date range: 2025-03-25 ‚Üí 2025-12-22\n",
            "[[11.792286   0.7996392 21.065529 ]]\n",
            "input_dim: 21 output_dim: 3 (outputs: [T, Ff, U])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = MCMCConfig(\n",
        "    K=3,\n",
        "    min_units=8,\n",
        "    max_units=128,\n",
        "    step=8,\n",
        "    iters=30,\n",
        "    temperature=0.0005,\n",
        "\n",
        "    train_epochs=50,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    dropout=0.1,\n",
        "    activation=\"relu\",\n",
        "\n",
        "    cache=True,\n",
        "    seed_base=12345\n",
        ")\n",
        "\n",
        "init_arch = [32, 32, 32]\n",
        "\n",
        "res = metropolis_hastings_arch_search(\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    input_dim=input_dim,\n",
        "    output_dim=output_dim,\n",
        "    init_arch=init_arch,\n",
        "    cfg=cfg,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\nBEST ARCH:\", res[\"best_arch\"])\n",
        "print(\"BEST VAL LOSS:\", res[\"best_loss\"])\n",
        "print(\"cache size:\", res[\"loss_cache_size\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXXS9vUolSy1",
        "outputId": "8aca35cd-4b71-4881-f69c-3cd0cea2eaf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start: arch=[32, 32, 32], val_loss=0.451857\n",
            "[001] ACCEPT ‚úÖ | prop=[24, 32, 32] 0.451526 | cur=[24, 32, 32] 0.451526 | best=[24, 32, 32] 0.451526 | p=1.000\n",
            "[002] ACCEPT ‚úÖ | prop=[24, 32, 24] 0.450167 | cur=[24, 32, 24] 0.450167 | best=[24, 32, 24] 0.450167 | p=1.000\n",
            "[003] ACCEPT ‚úÖ | prop=[32, 32, 24] 0.448730 | cur=[32, 32, 24] 0.448730 | best=[32, 32, 24] 0.448730 | p=1.000\n",
            "[004] reject ‚ùå | prop=[32, 32, 32] 0.451857 | cur=[32, 32, 24] 0.448730 | best=[32, 32, 24] 0.448730 | p=0.002\n",
            "[005] ACCEPT ‚úÖ | prop=[32, 40, 24] 0.446259 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=1.000\n",
            "[006] reject ‚ùå | prop=[40, 40, 24] 0.455089 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.000\n",
            "[007] reject ‚ùå | prop=[32, 48, 24] 0.454101 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.000\n",
            "[008] reject ‚ùå | prop=[32, 48, 24] 0.454101 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.000\n",
            "[009] reject ‚ùå | prop=[40, 40, 24] 0.455089 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.000\n",
            "[010] reject ‚ùå | prop=[40, 40, 24] 0.455089 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.000\n",
            "[011] reject ‚ùå | prop=[32, 40, 32] 0.449347 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.002\n",
            "[012] reject ‚ùå | prop=[32, 40, 16] 0.449177 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.003\n",
            "[013] reject ‚ùå | prop=[32, 32, 24] 0.448730 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.007\n",
            "[014] reject ‚ùå | prop=[24, 40, 24] 0.456604 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.000\n",
            "[015] reject ‚ùå | prop=[32, 40, 32] 0.449347 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.002\n",
            "[016] reject ‚ùå | prop=[32, 40, 32] 0.449347 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.002\n",
            "[017] reject ‚ùå | prop=[32, 40, 16] 0.449177 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.003\n",
            "[018] reject ‚ùå | prop=[32, 32, 24] 0.448730 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.007\n",
            "[019] reject ‚ùå | prop=[32, 40, 16] 0.449177 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.003\n",
            "[020] reject ‚ùå | prop=[32, 40, 32] 0.449347 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.002\n",
            "[021] reject ‚ùå | prop=[24, 40, 24] 0.456604 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.000\n",
            "[022] reject ‚ùå | prop=[32, 32, 24] 0.448730 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.007\n",
            "[023] reject ‚ùå | prop=[32, 40, 32] 0.449347 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.002\n",
            "[024] reject ‚ùå | prop=[24, 40, 24] 0.456604 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.000\n",
            "[025] reject ‚ùå | prop=[32, 40, 32] 0.449347 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.002\n",
            "[026] reject ‚ùå | prop=[32, 40, 16] 0.449177 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.003\n",
            "[027] reject ‚ùå | prop=[32, 40, 16] 0.449177 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.003\n",
            "[028] reject ‚ùå | prop=[32, 40, 16] 0.449177 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.003\n",
            "[029] reject ‚ùå | prop=[24, 40, 24] 0.456604 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.000\n",
            "[030] reject ‚ùå | prop=[32, 40, 32] 0.449347 | cur=[32, 40, 24] 0.446259 | best=[32, 40, 24] 0.446259 | p=0.002\n",
            "\n",
            "BEST ARCH: [32, 40, 24]\n",
            "BEST VAL LOSS: 0.4462593380375542\n",
            "cache size: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å: –æ–±—É—á–∞–µ–º –Ω–∞ train+val (—á—Ç–æ–±—ã —á–µ—Å—Ç–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö)\n",
        "X_trainval_n = np.vstack([X_train_n, X_val_n])\n",
        "y_trainval_n = np.vstack([y_train_n, y_val_n])\n",
        "\n",
        "trainval_loader = make_loader(X_trainval_n, y_trainval_n, bs=128, shuffle=True)\n",
        "\n",
        "best_arch = res[\"best_arch\"]\n",
        "\n",
        "def train_final(model, loader, epochs=40, lr=1e-3, weight_decay=1e-4):\n",
        "    loss_fn = nn.MSELoss()\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        if (ep+1) % 10 == 0:\n",
        "            vl = evaluate_loss(model, val_loader, loss_fn)\n",
        "            print(f\"epoch {ep+1}/{epochs} val_loss={vl:.6f}\")\n",
        "\n",
        "final_model = MLP(input_dim, output_dim, best_arch, activation=cfg.activation, dropout=cfg.dropout).to(device)\n",
        "train_final(final_model, trainval_loader, epochs=40, lr=cfg.lr, weight_decay=cfg.weight_decay)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnn-JGEYlY3w",
        "outputId": "5bfef51c-637d-40db-ffd9-6186e227fed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10/40 val_loss=0.489552\n",
            "epoch 20/40 val_loss=0.450756\n",
            "epoch 30/40 val_loss=0.431904\n",
            "epoch 40/40 val_loss=0.422949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def mc_dropout_predict(model: nn.Module, Xn: np.ndarray, n_samples: int = 300, q_lo=0.10, q_hi=0.90):\n",
        "    \"\"\"\n",
        "    MC Dropout: –≤–∫–ª—é—á–∞–µ–º train() –Ω–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ, —á—Ç–æ–±—ã dropout —Ä–∞–±–æ—Ç–∞–ª.\n",
        "    –í–æ–∑–≤—Ä–∞—â–∞–µ–º mean –∏ –∫–≤–∞–Ω—Ç–∏–ª–∏ (–∏–Ω—Ç–µ—Ä–≤–∞–ª).\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    Xt = torch.tensor(Xn, dtype=torch.float32).to(device)\n",
        "\n",
        "    preds = []\n",
        "    for _ in range(n_samples):\n",
        "        preds.append(model(Xt).detach().cpu().numpy())\n",
        "    preds = np.stack(preds, axis=0)\n",
        "\n",
        "    mean = preds.mean(axis=0)\n",
        "    lo = np.quantile(preds, q_lo, axis=0)\n",
        "    hi = np.quantile(preds, q_hi, axis=0)\n",
        "    return mean, lo, hi\n",
        "\n",
        "mean_n, lo_n, hi_n = mc_dropout_predict(final_model, X_test_n, n_samples=300, q_lo=0.10, q_hi=0.90)\n",
        "\n",
        "mean = denorm_y(mean_n)\n",
        "lo   = denorm_y(lo_n)\n",
        "hi   = denorm_y(hi_n)\n",
        "\n",
        "y_true = y_test\n",
        "\n",
        "# –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–∞–∂–¥–æ–º—É —Ç–∞—Ä–≥–µ—Ç—É: [T, Ff, U]\n",
        "mae = np.mean(np.abs(mean - y_true), axis=0)\n",
        "rmse = np.sqrt(np.mean((mean - y_true) ** 2, axis=0))\n",
        "\n",
        "coverage = np.mean((y_true >= lo) & (y_true <= hi), axis=0)\n",
        "\n",
        "print(\"\\nTEST metrics (outputs = [T, Ff, U])\")\n",
        "print(\"MAE :\", mae)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"Coverage in [p10, p90]:\", coverage)\n",
        "\n",
        "# –¥–µ–ª–∞—é –ø—Ä–∏–º–µ—Ä—ã\n",
        "for k in [0, -1]:\n",
        "    print(\"\\nDate:\", dates_test[k])\n",
        "    print(f\"T  pred={mean[k,0]:.2f}  interval=({lo[k,0]:.2f}, {hi[k,0]:.2f})  true={y_true[k,0]:.2f}\")\n",
        "    print(f\"Ff pred={mean[k,1]:.2f}  interval=({lo[k,1]:.2f}, {hi[k,1]:.2f})  true={y_true[k,1]:.2f}\")\n",
        "    print(f\"U  pred={mean[k,2]:.2f}  interval=({lo[k,2]:.2f}, {hi[k,2]:.2f})  true={y_true[k,2]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOCi_nzqldII",
        "outputId": "18c9f308-4bc1-42a9-818a-b33558d224cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TEST metrics (outputs = [T, Ff, U])\n",
            "MAE : [ 2.927533    0.65617114 12.8168    ]\n",
            "RMSE: [ 3.7904253   0.79216594 16.159353  ]\n",
            "Coverage in [p10, p90]: [0.55311355 0.003663   0.20512821]\n",
            "\n",
            "Date: 2025-03-25\n",
            "T  pred=9.31  interval=(6.83, 11.82)  true=5.90\n",
            "Ff pred=1.82  interval=(1.70, 1.91)  true=3.00\n",
            "U  pred=42.92  interval=(37.92, 49.02)  true=78.00\n",
            "\n",
            "Date: 2025-12-22\n",
            "T  pred=1.20  interval=(-1.17, 4.07)  true=0.00\n",
            "Ff pred=1.29  interval=(1.19, 1.40)  true=3.00\n",
            "U  pred=81.77  interval=(76.55, 86.71)  true=87.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_exam_day(df15: pd.DataFrame, exam_date: date, lookback_days: int = 7, n_samples: int = 500):\n",
        "\n",
        "    dfc = df15.copy()\n",
        "    dfc[\"date\"] = dfc[\"dt\"].dt.date\n",
        "    dfc = dfc.sort_values(\"dt\")\n",
        "\n",
        "    prev_dates = [exam_date - timedelta(days=i) for i in range(lookback_days, 0, -1)]\n",
        "\n",
        "    rows = []\n",
        "    for d in prev_dates:\n",
        "        r = dfc[dfc[\"date\"] == d]\n",
        "        if len(r) == 0:\n",
        "            raise ValueError(f\"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –Ω–∞ 15:00 –∑–∞ –¥–∞—Ç—É {d}. –ù—É–∂–Ω—ã 7 –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–Ω–µ–π –ø–æ–¥—Ä—è–¥.\")\n",
        "        rows.append(r.iloc[-1][[\"T\",\"Ff\",\"U\"]].to_numpy(np.float32))\n",
        "\n",
        "    X_exam = np.stack(rows, axis=0).reshape(1, -1)     # (1,21)\n",
        "    X_exam_n = norm_X(X_exam).astype(np.float32)\n",
        "\n",
        "    mean_n, lo_n, hi_n = mc_dropout_predict(final_model, X_exam_n, n_samples=n_samples, q_lo=0.10, q_hi=0.90)\n",
        "    mean = denorm_y(mean_n)[0]\n",
        "    lo   = denorm_y(lo_n)[0]\n",
        "    hi   = denorm_y(hi_n)[0]\n",
        "\n",
        "    return mean, lo, hi\n",
        "\n",
        "last_date = df15[\"date\"].iloc[-1]\n",
        "exam_date = last_date + timedelta(days=1)\n",
        "print(\"Using exam_date =\", exam_date)\n",
        "\n",
        "mean_e, lo_e, hi_e = predict_exam_day(df15, exam_date, lookback_days=7, n_samples=500)\n",
        "\n",
        "print(\"\\nForecast for 15:00 on exam day (outputs = [T, Ff, U])\")\n",
        "print(f\"T  = {mean_e[0]:.2f}  (p10..p90: {lo_e[0]:.2f} .. {hi_e[0]:.2f})\")\n",
        "print(f\"Ff = {mean_e[1]:.2f}  (p10..p90: {lo_e[1]:.2f} .. {hi_e[1]:.2f})\")\n",
        "print(f\"U  = {mean_e[2]:.2f}  (p10..p90: {lo_e[2]:.2f} .. {hi_e[2]:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9Pwc00Rlgj5",
        "outputId": "92a236d2-3f05-420c-e3b4-69aaf76cf7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using exam_date = 2025-12-23\n",
            "\n",
            "Forecast for 15:00 on exam day (outputs = [T, Ff, U])\n",
            "T  = -1.33  (p10..p90: -4.08 .. 1.40)\n",
            "Ff = 1.37  (p10..p90: 1.28 .. 1.47)\n",
            "U  = 80.95  (p10..p90: 75.80 .. 85.81)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **–ü—É–Ω–∫—Ç D**"
      ],
      "metadata": {
        "id": "MGlitvfEuwIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "\n",
        "def _sync_if_cuda():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_loss(model: nn.Module, loader, loss_fn) -> float:\n",
        "    model.eval()\n",
        "    total_loss, total_n = 0.0, 0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        pred = model(xb)\n",
        "        loss = loss_fn(pred, yb)\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "        total_n += xb.size(0)\n",
        "    return total_loss / max(total_n, 1)\n",
        "\n",
        "\n",
        "def train_model_epochs(model, train_loader, loss_fn, optimizer, epochs: int) -> Dict[str, Any]:\n",
        "    model.train()\n",
        "    steps = 0\n",
        "    for _ in range(epochs):\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            steps += 1\n",
        "    return {\"steps\": steps, \"epochs_done\": epochs}\n",
        "\n",
        "\n",
        "def train_model_time(model, train_loader, loss_fn, optimizer, time_budget_s: float) -> Dict[str, Any]:\n",
        "    model.train()\n",
        "    steps = 0\n",
        "    epochs_done = 0\n",
        "\n",
        "    _sync_if_cuda()\n",
        "    t_end = time.perf_counter() + float(time_budget_s)\n",
        "\n",
        "    while True:\n",
        "        batches_in_this_epoch = 0\n",
        "\n",
        "        for xb, yb in train_loader:\n",
        "            # –µ—Å–ª–∏ –≤—Ä–µ–º—è –∑–∞–∫–æ–Ω—á–∏–ª–æ—Å—å ‚Äî –≤—ã—Ö–æ–¥–∏–º –ù–ï —É–≤–µ–ª–∏—á–∏–≤–∞—è epochs_done\n",
        "            if time.perf_counter() >= t_end:\n",
        "                _sync_if_cuda()\n",
        "                return {\n",
        "                    \"steps\": steps,\n",
        "                    \"epochs_done\": epochs_done,                 # —Ç–æ–ª—å–∫–æ –ü–û–õ–ù–´–ï —ç–ø–æ—Ö–∏\n",
        "                    \"batches_in_last_epoch\": batches_in_this_epoch,\n",
        "                    \"time_budget_s\": time_budget_s\n",
        "                }\n",
        "\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            steps += 1\n",
        "            batches_in_this_epoch += 1\n",
        "\n",
        "        # –¥–æ—à–ª–∏ –¥–æ –∫–æ–Ω—Ü–∞ train_loader => –∑–∞–≤–µ—Ä—à–∏–ª–∏ —ç–ø–æ—Ö—É\n",
        "        epochs_done += 1\n",
        "\n",
        "\n",
        "\n",
        "def train_and_get_val_loss_budget(\n",
        "    arch: List[int],\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    input_dim: int,\n",
        "    output_dim: int,\n",
        "    activation: str = \"relu\",\n",
        "    dropout: float = 0.0,\n",
        "    lr: float = 1e-3,\n",
        "    weight_decay: float = 0.0,\n",
        "    budget_mode: str = \"epochs\",         # \"epochs\" | \"time\"\n",
        "    train_epochs: int = 10,\n",
        "    train_time_s: float = 5.0,\n",
        "    seed_for_arch: Optional[int] = None,\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    if seed_for_arch is not None:\n",
        "        random.seed(seed_for_arch)\n",
        "        np.random.seed(seed_for_arch)\n",
        "        torch.manual_seed(seed_for_arch)\n",
        "        torch.cuda.manual_seed_all(seed_for_arch)\n",
        "\n",
        "    model = MLP(input_dim, output_dim, arch, activation=activation, dropout=dropout).to(device)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    _sync_if_cuda()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    if budget_mode == \"epochs\":\n",
        "        train_info = train_model_epochs(model, train_loader, loss_fn, optimizer, epochs=train_epochs)\n",
        "    elif budget_mode == \"time\":\n",
        "        train_info = train_model_time(model, train_loader, loss_fn, optimizer, time_budget_s=train_time_s)\n",
        "    else:\n",
        "        raise ValueError(\"budget_mode must be 'epochs' or 'time'\")\n",
        "\n",
        "    _sync_if_cuda()\n",
        "    train_seconds = time.perf_counter() - t0\n",
        "\n",
        "    val_loss = evaluate_loss(model, val_loader, loss_fn)\n",
        "\n",
        "    return {\n",
        "        \"val_loss\": float(val_loss),\n",
        "        \"train_seconds\": float(train_seconds),\n",
        "        **train_info,\n",
        "        \"arch\": arch.copy()\n",
        "    }\n"
      ],
      "metadata": {
        "id": "ybz01WucyKBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class MCMCConfigD:\n",
        "    K: int = 3\n",
        "    min_units: int = 8\n",
        "    max_units: int = 128\n",
        "    step: int = 8\n",
        "    iters: int = 30\n",
        "    temperature: float = 0.05\n",
        "\n",
        "    activation: str = \"relu\"\n",
        "    dropout: float = 0.1\n",
        "    lr: float = 1e-3\n",
        "    weight_decay: float = 1e-4\n",
        "\n",
        "    budget_mode: str = \"epochs\"  # \"epochs\" | \"time\"\n",
        "    train_epochs: int = 10\n",
        "    train_time_s: float = 5.0\n",
        "\n",
        "    cache: bool = True\n",
        "    seed_base: int = 12345\n",
        "\n",
        "\n",
        "def metropolis_hastings_arch_search_budget(\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    input_dim: int,\n",
        "    output_dim: int,\n",
        "    init_arch: List[int],\n",
        "    cfg: MCMCConfigD,\n",
        "    verbose: bool = True\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    assert len(init_arch) == cfg.K\n",
        "\n",
        "    cache: Dict[Tuple[int, ...], Dict[str, Any]] = {}\n",
        "\n",
        "    def get_eval(arch: List[int]) -> Dict[str, Any]:\n",
        "        key = tuple(arch)\n",
        "        if cfg.cache and key in cache:\n",
        "            return cache[key]\n",
        "\n",
        "        seed_for_arch = cfg.seed_base + (abs(hash(key)) % 100000)\n",
        "\n",
        "        out = train_and_get_val_loss_budget(\n",
        "            arch=arch,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            input_dim=input_dim,\n",
        "            output_dim=output_dim,\n",
        "            activation=cfg.activation,\n",
        "            dropout=cfg.dropout,\n",
        "            lr=cfg.lr,\n",
        "            weight_decay=cfg.weight_decay,\n",
        "            budget_mode=cfg.budget_mode,\n",
        "            train_epochs=cfg.train_epochs,\n",
        "            train_time_s=cfg.train_time_s,\n",
        "            seed_for_arch=seed_for_arch\n",
        "        )\n",
        "\n",
        "        if cfg.cache:\n",
        "            cache[key] = out\n",
        "        return out\n",
        "\n",
        "    cur_arch = init_arch.copy()\n",
        "    cur_eval = get_eval(cur_arch)\n",
        "    cur_loss = float(cur_eval[\"val_loss\"])\n",
        "\n",
        "    best_arch = cur_arch.copy()\n",
        "    best_loss = cur_loss\n",
        "\n",
        "    history: List[Dict[str, Any]] = []\n",
        "    total_train_seconds = 0.0\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Start ({cfg.budget_mode}): arch={cur_arch} val_loss={cur_loss:.6f}\")\n",
        "\n",
        "    for t in range(cfg.iters):\n",
        "        prop_arch = propose_architecture(cur_arch, cfg.min_units, cfg.max_units, cfg.step)\n",
        "        prop_eval = get_eval(prop_arch)\n",
        "        prop_loss = float(prop_eval[\"val_loss\"])\n",
        "\n",
        "        total_train_seconds += float(prop_eval.get(\"train_seconds\", 0.0))\n",
        "\n",
        "        delta = prop_loss - cur_loss\n",
        "        if delta <= 0:\n",
        "            acc_prob = 1.0\n",
        "        else:\n",
        "            acc_prob = math.exp(-delta / max(cfg.temperature, 1e-12))\n",
        "\n",
        "        accepted = (random.random() < acc_prob)\n",
        "\n",
        "        if accepted:\n",
        "            cur_arch = prop_arch\n",
        "            cur_loss = prop_loss\n",
        "\n",
        "        if cur_loss < best_loss:\n",
        "            best_loss = cur_loss\n",
        "            best_arch = cur_arch.copy()\n",
        "\n",
        "        history.append({\n",
        "            \"iter\": t + 1,\n",
        "            \"cur_arch\": cur_arch.copy(),\n",
        "            \"cur_loss\": float(cur_loss),\n",
        "            \"prop_arch\": prop_arch.copy(),\n",
        "            \"prop_loss\": float(prop_loss),\n",
        "            \"accepted\": bool(accepted),\n",
        "            \"acc_prob\": float(acc_prob),\n",
        "            \"prop_train_seconds\": float(prop_eval.get(\"train_seconds\", 0.0)),\n",
        "            \"prop_steps\": int(prop_eval.get(\"steps\", -1)),\n",
        "            \"prop_epochs_done\": int(prop_eval.get(\"epochs_done\", -1)),\n",
        "            \"best_arch\": best_arch.copy(),\n",
        "            \"best_loss\": float(best_loss),\n",
        "        })\n",
        "\n",
        "        if verbose:\n",
        "            tag = \"ACCEPT ‚úÖ\" if accepted else \"reject ‚ùå\"\n",
        "            ep_done = int(prop_eval.get(\"epochs_done\", -1))\n",
        "            sec = float(prop_eval.get(\"train_seconds\", 0.0))\n",
        "            print(\n",
        "                f\"[{t+1:03d}] {tag} | \"\n",
        "                f\"prop={prop_arch} loss={prop_loss:.6f} | \"\n",
        "                f\"epochs_done={ep_done} time={sec:.2f}s | \"\n",
        "                f\"cur={cur_arch} loss={cur_loss:.6f} | \"\n",
        "                f\"best={best_arch} {best_loss:.6f} | \"\n",
        "                f\"p={acc_prob:.3f}\"\n",
        "            )\n",
        "\n",
        "    acc_rate = float(np.mean([h[\"accepted\"] for h in history])) if history else 0.0\n",
        "\n",
        "    return {\n",
        "        \"best_arch\": best_arch,\n",
        "        \"best_loss\": best_loss,\n",
        "        \"history\": history,\n",
        "        \"acceptance_rate\": acc_rate,\n",
        "        \"total_train_seconds\": float(total_train_seconds),\n",
        "        \"cache_size\": len(cache),\n",
        "        \"cfg\": cfg,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "D-0IAFD3yLmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –í—ã–±–∏—Ä–∞–µ–º –±–∞–∑–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏ —á–∏—Å–ª–æ —ç–ø–æ—Ö –¥–ª—è —Ä–µ–∂–∏–º–∞ A\n",
        "init_arch = [32, 32, 32]  # –∏–ª–∏ —Ç–æ, —Å —á–µ–≥–æ —Ç—ã —Å—Ç–∞—Ä—Ç–æ–≤–∞–ª–∞ –≤ (c)\n",
        "E = 10\n",
        "\n",
        "# 1) –∏–∑–º–µ—Ä–∏–º, —Å–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏ –≤ —Å—Ä–µ–¥–Ω–µ–º –∑–∞–Ω–∏–º–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ E —ç–ø–æ—Ö –Ω–∞ init_arch\n",
        "probe = train_and_get_val_loss_budget(\n",
        "    arch=init_arch,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    input_dim=input_dim,\n",
        "    output_dim=output_dim,\n",
        "    activation=\"relu\",\n",
        "    dropout=0.1,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    budget_mode=\"epochs\",\n",
        "    train_epochs=E,\n",
        "    seed_for_arch=777\n",
        ")\n",
        "\n",
        "time_budget = probe[\"train_seconds\"]\n",
        "print(f\"–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞: {E} —ç–ø–æ—Ö –Ω–∞ arch={init_arch} –∑–∞–Ω—è–ª–∏ ~ {time_budget:.2f} —Å–µ–∫—É–Ω–¥.\")\n",
        "print(f\"–ó–Ω–∞—á–∏—Ç –¥–ª—è —Ä–µ–∂–∏–º–∞ 'time' –±–µ—Ä—ë–º train_time_s = {time_budget:.2f} (–ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –±—é–¥–∂–µ—Ç).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUd1wI5gyPW6",
        "outputId": "19a72a47-5acd-4b56-9def-a8ad6848116e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞: 10 —ç–ø–æ—Ö –Ω–∞ arch=[32, 32, 32] –∑–∞–Ω—è–ª–∏ ~ 0.48 —Å–µ–∫—É–Ω–¥.\n",
            "–ó–Ω–∞—á–∏—Ç –¥–ª—è —Ä–µ–∂–∏–º–∞ 'time' –±–µ—Ä—ë–º train_time_s = 0.48 (–ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –±—é–¥–∂–µ—Ç).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –†–µ–∂–∏–º A: —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç–ø–æ—Ö–∏\n",
        "cfg_epochs = MCMCConfigD(\n",
        "    K=3,\n",
        "    min_units=8, max_units=128, step=8,\n",
        "    iters=30,\n",
        "    temperature=0.05,\n",
        "    activation=\"relu\",\n",
        "    dropout=0.1,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    budget_mode=\"epochs\",\n",
        "    train_epochs=E,\n",
        "    train_time_s=0.0,\n",
        "    cache=True\n",
        ")\n",
        "\n",
        "res_epochs = metropolis_hastings_arch_search_budget(\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    input_dim=input_dim,\n",
        "    output_dim=output_dim,\n",
        "    init_arch=init_arch,\n",
        "    cfg=cfg_epochs,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\n=== –ò—Ç–æ–≥ —Ä–µ–∂–∏–º–∞ epochs ===\")\n",
        "print(\"best_arch:\", res_epochs[\"best_arch\"])\n",
        "print(\"best_loss:\", res_epochs[\"best_loss\"])\n",
        "print(\"acceptance_rate:\", res_epochs[\"acceptance_rate\"])\n",
        "print(\"total_train_seconds (approx):\", res_epochs[\"total_train_seconds\"])\n",
        "\n",
        "epochs_list = [h[\"prop_epochs_done\"] for h in res_epochs[\"history\"]]\n",
        "print(\"epochs_done values (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ):\", sorted(set(epochs_list)))\n",
        "print(\"expected fixed epochs =\", E)\n",
        "\n",
        "\n",
        "# –†–µ–∂–∏–º B: —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è\n",
        "cfg_time = MCMCConfigD(\n",
        "    K=3,\n",
        "    min_units=8, max_units=128, step=8,\n",
        "    iters=30,\n",
        "    temperature=0.005,\n",
        "    activation=\"relu\",\n",
        "    dropout=0.1,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    budget_mode=\"time\",\n",
        "    train_epochs=0,\n",
        "    train_time_s=float(time_budget),\n",
        "    cache=True\n",
        ")\n",
        "\n",
        "import time\n",
        "\n",
        "# --- –†–µ–∂–∏–º B: —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è (time) ---\n",
        "t_chain0 = time.perf_counter()\n",
        "\n",
        "res_time = metropolis_hastings_arch_search_budget(\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    input_dim=input_dim,\n",
        "    output_dim=output_dim,\n",
        "    init_arch=init_arch,\n",
        "    cfg=cfg_time,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "t_chain1 = time.perf_counter()\n",
        "wall = t_chain1 - t_chain0\n",
        "\n",
        "expected = cfg_time.iters * cfg_time.train_time_s\n",
        "print(\"\\n[Time-mode budget check]\")\n",
        "print(\"EXPECTED budget (iters * time_budget):\", expected)\n",
        "print(\"WALL-CLOCK time of whole run:\", wall)\n",
        "\n",
        "\n",
        "print(\"\\n=== –ò—Ç–æ–≥ —Ä–µ–∂–∏–º–∞ time ===\")\n",
        "print(\"best_arch:\", res_time[\"best_arch\"])\n",
        "print(\"best_loss:\", res_time[\"best_loss\"])\n",
        "print(\"acceptance_rate:\", res_time[\"acceptance_rate\"])\n",
        "print(\"total_train_seconds (approx):\", res_time[\"total_train_seconds\"])\n",
        "\n",
        "epochs_list_t = np.array([h[\"prop_epochs_done\"] for h in res_time[\"history\"]], dtype=float)\n",
        "print(\"epochs_done stats (time-mode):\")\n",
        "print(\"  min :\", int(np.min(epochs_list_t)))\n",
        "print(\"  mean:\", float(np.mean(epochs_list_t)))\n",
        "print(\"  max :\", int(np.max(epochs_list_t)))\n",
        "print(\"time_budget_s per eval =\", cfg_time.train_time_s)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj2P_HJHyU83",
        "outputId": "75b64461-253d-40a7-ef52-e04f8a7409e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start (epochs): arch=[32, 32, 32] val_loss=0.471412\n",
            "[001] ACCEPT ‚úÖ | prop=[24, 32, 32] loss=0.486095 | epochs_done=10 time=0.45s | cur=[24, 32, 32] loss=0.486095 | best=[32, 32, 32] 0.471412 | p=0.746\n",
            "[002] ACCEPT ‚úÖ | prop=[24, 32, 24] loss=0.494538 | epochs_done=10 time=0.50s | cur=[24, 32, 24] loss=0.494538 | best=[32, 32, 32] 0.471412 | p=0.845\n",
            "[003] ACCEPT ‚úÖ | prop=[32, 32, 24] loss=0.479516 | epochs_done=10 time=0.45s | cur=[32, 32, 24] loss=0.479516 | best=[32, 32, 32] 0.471412 | p=1.000\n",
            "[004] ACCEPT ‚úÖ | prop=[32, 32, 32] loss=0.471412 | epochs_done=10 time=0.45s | cur=[32, 32, 32] loss=0.471412 | best=[32, 32, 32] 0.471412 | p=1.000\n",
            "[005] reject ‚ùå | prop=[32, 40, 32] loss=0.489770 | epochs_done=10 time=0.33s | cur=[32, 32, 32] loss=0.471412 | best=[32, 32, 32] 0.471412 | p=0.693\n",
            "[006] ACCEPT ‚úÖ | prop=[32, 32, 24] loss=0.479516 | epochs_done=10 time=0.45s | cur=[32, 32, 24] loss=0.479516 | best=[32, 32, 32] 0.471412 | p=0.850\n",
            "[007] ACCEPT ‚úÖ | prop=[32, 32, 16] loss=0.508325 | epochs_done=10 time=0.31s | cur=[32, 32, 16] loss=0.508325 | best=[32, 32, 32] 0.471412 | p=0.562\n",
            "[008] ACCEPT ‚úÖ | prop=[32, 24, 16] loss=0.484365 | epochs_done=10 time=0.32s | cur=[32, 24, 16] loss=0.484365 | best=[32, 32, 32] 0.471412 | p=1.000\n",
            "[009] ACCEPT ‚úÖ | prop=[32, 16, 16] loss=0.501608 | epochs_done=10 time=0.31s | cur=[32, 16, 16] loss=0.501608 | best=[32, 32, 32] 0.471412 | p=0.708\n",
            "[010] reject ‚ùå | prop=[32, 16, 8] loss=0.617277 | epochs_done=10 time=0.31s | cur=[32, 16, 16] loss=0.501608 | best=[32, 32, 32] 0.471412 | p=0.099\n",
            "[011] ACCEPT ‚úÖ | prop=[32, 24, 16] loss=0.484365 | epochs_done=10 time=0.32s | cur=[32, 24, 16] loss=0.484365 | best=[32, 32, 32] 0.471412 | p=1.000\n",
            "[012] ACCEPT ‚úÖ | prop=[32, 24, 24] loss=0.490054 | epochs_done=10 time=0.30s | cur=[32, 24, 24] loss=0.490054 | best=[32, 32, 32] 0.471412 | p=0.892\n",
            "[013] ACCEPT ‚úÖ | prop=[32, 32, 24] loss=0.479516 | epochs_done=10 time=0.45s | cur=[32, 32, 24] loss=0.479516 | best=[32, 32, 32] 0.471412 | p=1.000\n",
            "[014] ACCEPT ‚úÖ | prop=[32, 32, 16] loss=0.508325 | epochs_done=10 time=0.31s | cur=[32, 32, 16] loss=0.508325 | best=[32, 32, 32] 0.471412 | p=0.562\n",
            "[015] ACCEPT ‚úÖ | prop=[32, 24, 16] loss=0.484365 | epochs_done=10 time=0.32s | cur=[32, 24, 16] loss=0.484365 | best=[32, 32, 32] 0.471412 | p=1.000\n",
            "[016] ACCEPT ‚úÖ | prop=[32, 24, 24] loss=0.490054 | epochs_done=10 time=0.30s | cur=[32, 24, 24] loss=0.490054 | best=[32, 32, 32] 0.471412 | p=0.892\n",
            "[017] ACCEPT ‚úÖ | prop=[32, 24, 16] loss=0.484365 | epochs_done=10 time=0.32s | cur=[32, 24, 16] loss=0.484365 | best=[32, 32, 32] 0.471412 | p=1.000\n",
            "[018] ACCEPT ‚úÖ | prop=[32, 32, 16] loss=0.508325 | epochs_done=10 time=0.31s | cur=[32, 32, 16] loss=0.508325 | best=[32, 32, 32] 0.471412 | p=0.619\n",
            "[019] ACCEPT ‚úÖ | prop=[32, 40, 16] loss=0.497092 | epochs_done=10 time=0.32s | cur=[32, 40, 16] loss=0.497092 | best=[32, 32, 32] 0.471412 | p=1.000\n",
            "[020] ACCEPT ‚úÖ | prop=[32, 32, 16] loss=0.508325 | epochs_done=10 time=0.31s | cur=[32, 32, 16] loss=0.508325 | best=[32, 32, 32] 0.471412 | p=0.799\n",
            "[021] ACCEPT ‚úÖ | prop=[24, 32, 16] loss=0.485820 | epochs_done=10 time=0.31s | cur=[24, 32, 16] loss=0.485820 | best=[32, 32, 32] 0.471412 | p=1.000\n",
            "[022] reject ‚ùå | prop=[24, 32, 8] loss=0.503829 | epochs_done=10 time=0.30s | cur=[24, 32, 16] loss=0.485820 | best=[32, 32, 32] 0.471412 | p=0.698\n",
            "[023] reject ‚ùå | prop=[24, 32, 24] loss=0.494538 | epochs_done=10 time=0.50s | cur=[24, 32, 16] loss=0.485820 | best=[32, 32, 32] 0.471412 | p=0.840\n",
            "[024] ACCEPT ‚úÖ | prop=[24, 32, 24] loss=0.494538 | epochs_done=10 time=0.50s | cur=[24, 32, 24] loss=0.494538 | best=[32, 32, 32] 0.471412 | p=0.840\n",
            "[025] ACCEPT ‚úÖ | prop=[32, 32, 24] loss=0.479516 | epochs_done=10 time=0.45s | cur=[32, 32, 24] loss=0.479516 | best=[32, 32, 32] 0.471412 | p=1.000\n",
            "[026] ACCEPT ‚úÖ | prop=[32, 32, 16] loss=0.508325 | epochs_done=10 time=0.31s | cur=[32, 32, 16] loss=0.508325 | best=[32, 32, 32] 0.471412 | p=0.562\n",
            "[027] reject ‚ùå | prop=[32, 32, 8] loss=0.588525 | epochs_done=10 time=0.33s | cur=[32, 32, 16] loss=0.508325 | best=[32, 32, 32] 0.471412 | p=0.201\n",
            "[028] ACCEPT ‚úÖ | prop=[32, 40, 16] loss=0.497092 | epochs_done=10 time=0.32s | cur=[32, 40, 16] loss=0.497092 | best=[32, 32, 32] 0.471412 | p=1.000\n",
            "[029] ACCEPT ‚úÖ | prop=[32, 40, 24] loss=0.474632 | epochs_done=10 time=0.31s | cur=[32, 40, 24] loss=0.474632 | best=[32, 32, 32] 0.471412 | p=1.000\n",
            "[030] ACCEPT ‚úÖ | prop=[40, 40, 24] loss=0.476597 | epochs_done=10 time=0.32s | cur=[40, 40, 24] loss=0.476597 | best=[32, 32, 32] 0.471412 | p=0.961\n",
            "\n",
            "=== –ò—Ç–æ–≥ —Ä–µ–∂–∏–º–∞ epochs ===\n",
            "best_arch: [32, 32, 32]\n",
            "best_loss: 0.4714124849361687\n",
            "acceptance_rate: 0.8333333333333334\n",
            "total_train_seconds (approx): 10.82060930800003\n",
            "epochs_done values (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ): [10]\n",
            "expected fixed epochs = 10\n",
            "Start (time): arch=[32, 32, 32] val_loss=0.458714\n",
            "[001] ACCEPT ‚úÖ | prop=[24, 32, 32] loss=0.466800 | epochs_done=15 time=0.48s | cur=[24, 32, 32] loss=0.466800 | best=[32, 32, 32] 0.458714 | p=0.851\n",
            "[002] ACCEPT ‚úÖ | prop=[24, 32, 24] loss=0.476912 | epochs_done=12 time=0.48s | cur=[24, 32, 24] loss=0.476912 | best=[32, 32, 32] 0.458714 | p=0.817\n",
            "[003] ACCEPT ‚úÖ | prop=[32, 32, 24] loss=0.463891 | epochs_done=11 time=0.48s | cur=[32, 32, 24] loss=0.463891 | best=[32, 32, 32] 0.458714 | p=1.000\n",
            "[004] ACCEPT ‚úÖ | prop=[32, 32, 32] loss=0.458714 | epochs_done=14 time=0.48s | cur=[32, 32, 32] loss=0.458714 | best=[32, 32, 32] 0.458714 | p=1.000\n",
            "[005] ACCEPT ‚úÖ | prop=[32, 40, 32] loss=0.463478 | epochs_done=14 time=0.48s | cur=[32, 40, 32] loss=0.463478 | best=[32, 32, 32] 0.458714 | p=0.909\n",
            "[006] ACCEPT ‚úÖ | prop=[32, 40, 24] loss=0.463534 | epochs_done=13 time=0.48s | cur=[32, 40, 24] loss=0.463534 | best=[32, 32, 32] 0.458714 | p=0.999\n",
            "[007] ACCEPT ‚úÖ | prop=[40, 40, 24] loss=0.467420 | epochs_done=13 time=0.48s | cur=[40, 40, 24] loss=0.467420 | best=[32, 32, 32] 0.458714 | p=0.925\n",
            "[008] ACCEPT ‚úÖ | prop=[40, 48, 24] loss=0.467890 | epochs_done=14 time=0.48s | cur=[40, 48, 24] loss=0.467890 | best=[32, 32, 32] 0.458714 | p=0.991\n",
            "[009] ACCEPT ‚úÖ | prop=[48, 48, 24] loss=0.463912 | epochs_done=15 time=0.48s | cur=[48, 48, 24] loss=0.463912 | best=[32, 32, 32] 0.458714 | p=1.000\n",
            "[010] ACCEPT ‚úÖ | prop=[40, 48, 24] loss=0.467890 | epochs_done=14 time=0.48s | cur=[40, 48, 24] loss=0.467890 | best=[32, 32, 32] 0.458714 | p=0.924\n",
            "[011] ACCEPT ‚úÖ | prop=[40, 40, 24] loss=0.467420 | epochs_done=13 time=0.48s | cur=[40, 40, 24] loss=0.467420 | best=[32, 32, 32] 0.458714 | p=1.000\n",
            "[012] ACCEPT ‚úÖ | prop=[40, 48, 24] loss=0.467890 | epochs_done=14 time=0.48s | cur=[40, 48, 24] loss=0.467890 | best=[32, 32, 32] 0.458714 | p=0.991\n",
            "[013] ACCEPT ‚úÖ | prop=[40, 48, 32] loss=0.457340 | epochs_done=13 time=0.48s | cur=[40, 48, 32] loss=0.457340 | best=[40, 48, 32] 0.457340 | p=1.000\n",
            "[014] ACCEPT ‚úÖ | prop=[40, 56, 32] loss=0.457638 | epochs_done=14 time=0.48s | cur=[40, 56, 32] loss=0.457638 | best=[40, 48, 32] 0.457340 | p=0.994\n",
            "[015] ACCEPT ‚úÖ | prop=[40, 56, 40] loss=0.455483 | epochs_done=13 time=0.48s | cur=[40, 56, 40] loss=0.455483 | best=[40, 56, 40] 0.455483 | p=1.000\n",
            "[016] ACCEPT ‚úÖ | prop=[40, 56, 48] loss=0.468182 | epochs_done=11 time=0.48s | cur=[40, 56, 48] loss=0.468182 | best=[40, 56, 40] 0.455483 | p=0.776\n",
            "[017] ACCEPT ‚úÖ | prop=[40, 64, 48] loss=0.458243 | epochs_done=9 time=0.48s | cur=[40, 64, 48] loss=0.458243 | best=[40, 56, 40] 0.455483 | p=1.000\n",
            "[018] ACCEPT ‚úÖ | prop=[40, 72, 48] loss=0.458152 | epochs_done=9 time=0.48s | cur=[40, 72, 48] loss=0.458152 | best=[40, 56, 40] 0.455483 | p=1.000\n",
            "[019] ACCEPT ‚úÖ | prop=[40, 72, 40] loss=0.461829 | epochs_done=9 time=0.48s | cur=[40, 72, 40] loss=0.461829 | best=[40, 56, 40] 0.455483 | p=0.929\n",
            "[020] ACCEPT ‚úÖ | prop=[40, 80, 40] loss=0.477016 | epochs_done=9 time=0.48s | cur=[40, 80, 40] loss=0.477016 | best=[40, 56, 40] 0.455483 | p=0.738\n",
            "[021] ACCEPT ‚úÖ | prop=[32, 80, 40] loss=0.465908 | epochs_done=8 time=0.48s | cur=[32, 80, 40] loss=0.465908 | best=[40, 56, 40] 0.455483 | p=1.000\n",
            "[022] ACCEPT ‚úÖ | prop=[32, 80, 48] loss=0.453945 | epochs_done=13 time=0.48s | cur=[32, 80, 48] loss=0.453945 | best=[32, 80, 48] 0.453945 | p=1.000\n",
            "[023] ACCEPT ‚úÖ | prop=[32, 72, 48] loss=0.455460 | epochs_done=13 time=0.48s | cur=[32, 72, 48] loss=0.455460 | best=[32, 80, 48] 0.453945 | p=0.970\n",
            "[024] ACCEPT ‚úÖ | prop=[32, 64, 48] loss=0.463357 | epochs_done=13 time=0.48s | cur=[32, 64, 48] loss=0.463357 | best=[32, 80, 48] 0.453945 | p=0.854\n",
            "[025] ACCEPT ‚úÖ | prop=[32, 64, 56] loss=0.466734 | epochs_done=12 time=0.48s | cur=[32, 64, 56] loss=0.466734 | best=[32, 80, 48] 0.453945 | p=0.935\n",
            "[026] ACCEPT ‚úÖ | prop=[40, 64, 56] loss=0.460009 | epochs_done=13 time=0.48s | cur=[40, 64, 56] loss=0.460009 | best=[32, 80, 48] 0.453945 | p=1.000\n",
            "[027] ACCEPT ‚úÖ | prop=[40, 56, 56] loss=0.454096 | epochs_done=14 time=0.48s | cur=[40, 56, 56] loss=0.454096 | best=[32, 80, 48] 0.453945 | p=1.000\n",
            "[028] ACCEPT ‚úÖ | prop=[48, 56, 56] loss=0.449890 | epochs_done=13 time=0.48s | cur=[48, 56, 56] loss=0.449890 | best=[48, 56, 56] 0.449890 | p=1.000\n",
            "[029] ACCEPT ‚úÖ | prop=[48, 56, 64] loss=0.451983 | epochs_done=13 time=0.48s | cur=[48, 56, 64] loss=0.451983 | best=[48, 56, 56] 0.449890 | p=0.959\n",
            "[030] ACCEPT ‚úÖ | prop=[40, 56, 64] loss=0.462855 | epochs_done=12 time=0.48s | cur=[40, 56, 64] loss=0.462855 | best=[48, 56, 56] 0.449890 | p=0.805\n",
            "\n",
            "[Time-mode budget check]\n",
            "EXPECTED budget (iters * time_budget): 14.384826690000523\n",
            "WALL-CLOCK time of whole run: 13.182507122999993\n",
            "\n",
            "=== –ò—Ç–æ–≥ —Ä–µ–∂–∏–º–∞ time ===\n",
            "best_arch: [48, 56, 56]\n",
            "best_loss: 0.44989028276112686\n",
            "acceptance_rate: 1.0\n",
            "total_train_seconds (approx): 14.438450576999855\n",
            "epochs_done stats (time-mode):\n",
            "  min : 8\n",
            "  mean: 12.433333333333334\n",
            "  max : 15\n",
            "time_budget_s per eval = 0.4794942230000174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **–ü—É–Ω–∫—Ç E**"
      ],
      "metadata": {
        "id": "5Y6-EI9RR-ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        output_dim: int,\n",
        "        arch: List[int],\n",
        "        activation=\"relu\",       # str –∏–ª–∏ List[str] –¥–ª–∏–Ω—ã len(arch)\n",
        "        dropout: float = 0.0\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        act_map = {\n",
        "            \"relu\": nn.ReLU,\n",
        "            \"tanh\": nn.Tanh,\n",
        "            \"gelu\": nn.GELU,\n",
        "            \"sigmoid\": nn.Sigmoid\n",
        "        }\n",
        "\n",
        "\n",
        "        if isinstance(activation, str):\n",
        "            activations = [activation.lower()] * len(arch)\n",
        "        else:\n",
        "            activations = [str(a).lower() for a in activation]\n",
        "            if len(activations) != len(arch):\n",
        "                raise ValueError(\"activation list must have same length as arch\")\n",
        "\n",
        "        layers = []\n",
        "        prev = input_dim\n",
        "\n",
        "        for width, act_name in zip(arch, activations):\n",
        "            if act_name not in act_map:\n",
        "                raise ValueError(f\"Unknown activation: {act_name}. Allowed: {list(act_map.keys())}\")\n",
        "            layers.append(nn.Linear(prev, width))\n",
        "            layers.append(act_map[act_name]())\n",
        "            if dropout and dropout > 0:\n",
        "                layers.append(nn.Dropout(dropout))\n",
        "            prev = width\n",
        "\n",
        "        layers.append(nn.Linear(prev, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "C-adqA8GSBQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Tuple, List, Dict, Any\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "@dataclass\n",
        "class MCMCConfigE:\n",
        "    K: int = 3\n",
        "    min_units: int = 8\n",
        "    max_units: int = 128\n",
        "    step: int = 8\n",
        "    iters: int = 30\n",
        "    temperature: float = 0.05\n",
        "\n",
        "    budget_mode: str = \"epochs\"     # \"epochs\" | \"time\"\n",
        "    train_epochs: int = 10\n",
        "    train_time_s: float = 0.5\n",
        "\n",
        "    lr: float = 1e-3\n",
        "    weight_decay: float = 1e-4\n",
        "    dropout: float = 0.1\n",
        "\n",
        "    # –ø—É–Ω–∫—Ç E: –∫–∞–∫–∏–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω—ã + –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —à–∞–≥–∞ –ø–æ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\n",
        "    allowed_activations: Tuple[str, ...] = (\"relu\", \"tanh\", \"gelu\", \"sigmoid\")\n",
        "    p_change_activation: float = 0.30   # 30% —à–∞–≥–æ–≤ –º–µ–Ω—è—é—Ç activation, 70% –º–µ–Ω—è—é—Ç —à–∏—Ä–∏–Ω—É\n",
        "\n",
        "    cache: bool = True\n",
        "    seed_base: int = 12345\n",
        "\n",
        "\n",
        "def propose_state_with_activation(\n",
        "    arch: Tuple[int, ...],\n",
        "    acts: Tuple[str, ...],\n",
        "    cfg: MCMCConfigE\n",
        ") -> Tuple[Tuple[int, ...], Tuple[str, ...]]:\n",
        "    \"\"\"\n",
        "    –°–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π proposal:\n",
        "    - —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é p: –º–µ–Ω—è–µ–º activation –æ–¥–Ω–æ–≥–æ —Å–ª–æ—è\n",
        "    - –∏–Ω–∞—á–µ: –º–µ–Ω—è–µ–º —à–∏—Ä–∏–Ω—É –æ–¥–Ω–æ–≥–æ —Å–ª–æ—è –Ω–∞ ¬±step (–≤ –≥—Ä–∞–Ω–∏—Ü–∞—Ö), –∏–Ω–∞—á–µ –Ω—É–ª–µ–≤–æ–π —Ö–æ–¥\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) —à–∞–≥ –ø–æ activation\n",
        "    if random.random() < cfg.p_change_activation:\n",
        "        i = random.randrange(cfg.K)\n",
        "        cur = acts[i]\n",
        "        choices = [a for a in cfg.allowed_activations if a != cur]\n",
        "        if not choices:\n",
        "            return arch, acts  # –Ω—É–ª–µ–≤–æ–π —Ö–æ–¥\n",
        "        new_act = random.choice(choices)\n",
        "\n",
        "        new_acts = list(acts)\n",
        "        new_acts[i] = new_act\n",
        "        return arch, tuple(new_acts)\n",
        "\n",
        "    # 2) —à–∞–≥ –ø–æ —à–∏—Ä–∏–Ω–µ —Å–ª–æ—è (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)\n",
        "    new_arch = list(arch)\n",
        "    i = random.randrange(cfg.K)\n",
        "    direction = random.choice([-1, +1])\n",
        "    cand = new_arch[i] + direction * cfg.step\n",
        "\n",
        "    if cand < cfg.min_units or cand > cfg.max_units:\n",
        "        return arch, acts  # –Ω—É–ª–µ–≤–æ–π —Ö–æ–¥\n",
        "\n",
        "    new_arch[i] = int(cand)\n",
        "    return tuple(new_arch), acts\n"
      ],
      "metadata": {
        "id": "J4JzeD5dSER7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metropolis_hastings_search_arch_and_activation(\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    input_dim: int,\n",
        "    output_dim: int,\n",
        "    init_arch: List[int],\n",
        "    init_acts: List[str],\n",
        "    cfg: MCMCConfigE,\n",
        "    verbose: bool = True\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    assert len(init_arch) == cfg.K\n",
        "    assert len(init_acts) == cfg.K\n",
        "\n",
        "    # cache –ø–æ –ø–æ–ª–Ω–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é (arch + acts)\n",
        "    cache: Dict[Tuple[Tuple[int, ...], Tuple[str, ...]], Dict[str, Any]] = {}\n",
        "\n",
        "    def get_eval(arch_t: Tuple[int, ...], acts_t: Tuple[str, ...]) -> Dict[str, Any]:\n",
        "        key = (arch_t, acts_t)\n",
        "        if cfg.cache and key in cache:\n",
        "            out = cache[key].copy()\n",
        "            out[\"_cached\"] = True\n",
        "            return out\n",
        "\n",
        "        seed_for_state = cfg.seed_base + (abs(hash(key)) % 100000)\n",
        "\n",
        "        out = train_and_get_val_loss_budget(\n",
        "            arch=list(arch_t),\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            input_dim=input_dim,\n",
        "            output_dim=output_dim,\n",
        "            activation=list(acts_t),       # <-- –í–û–¢ –û–ù–û: —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–∞—Ü–∏–π –ø–æ —Å–ª–æ—è–º\n",
        "            dropout=cfg.dropout,\n",
        "            lr=cfg.lr,\n",
        "            weight_decay=cfg.weight_decay,\n",
        "            budget_mode=cfg.budget_mode,\n",
        "            train_epochs=cfg.train_epochs,\n",
        "            train_time_s=cfg.train_time_s,\n",
        "            seed_for_arch=seed_for_state\n",
        "        )\n",
        "        out[\"_cached\"] = False\n",
        "\n",
        "        if cfg.cache:\n",
        "            cache[key] = out\n",
        "        return out\n",
        "\n",
        "    cur_arch = tuple(init_arch)\n",
        "    cur_acts = tuple(a.lower() for a in init_acts)\n",
        "\n",
        "    cur_eval = get_eval(cur_arch, cur_acts)\n",
        "    cur_loss = float(cur_eval[\"val_loss\"])\n",
        "\n",
        "    best_arch, best_acts = cur_arch, cur_acts\n",
        "    best_loss = cur_loss\n",
        "\n",
        "    history = []\n",
        "    if verbose:\n",
        "        print(f\"Start: arch={list(cur_arch)} acts={list(cur_acts)} val_loss={cur_loss:.6f}\")\n",
        "\n",
        "    for t in range(cfg.iters):\n",
        "        prop_arch, prop_acts = propose_state_with_activation(cur_arch, cur_acts, cfg)\n",
        "        prop_eval = get_eval(prop_arch, prop_acts)\n",
        "        prop_loss = float(prop_eval[\"val_loss\"])\n",
        "\n",
        "        delta = prop_loss - cur_loss\n",
        "        if delta <= 0:\n",
        "            acc_prob = 1.0\n",
        "        else:\n",
        "            acc_prob = math.exp(-delta / max(cfg.temperature, 1e-12))\n",
        "\n",
        "        accepted = (random.random() < acc_prob)\n",
        "        if accepted:\n",
        "            cur_arch, cur_acts, cur_loss = prop_arch, prop_acts, prop_loss\n",
        "\n",
        "        if cur_loss < best_loss:\n",
        "            best_arch, best_acts, best_loss = cur_arch, cur_acts, cur_loss\n",
        "\n",
        "        history.append({\n",
        "            \"iter\": t + 1,\n",
        "            \"cur_arch\": list(cur_arch),\n",
        "            \"cur_acts\": list(cur_acts),\n",
        "            \"cur_loss\": float(cur_loss),\n",
        "            \"prop_arch\": list(prop_arch),\n",
        "            \"prop_acts\": list(prop_acts),\n",
        "            \"prop_loss\": float(prop_loss),\n",
        "            \"accepted\": bool(accepted),\n",
        "            \"acc_prob\": float(acc_prob),\n",
        "            \"epochs_done\": int(prop_eval.get(\"epochs_done\", -1)),\n",
        "            \"train_seconds\": float(prop_eval.get(\"train_seconds\", 0.0)),\n",
        "            \"_cached\": bool(prop_eval.get(\"_cached\", False)),\n",
        "            \"best_arch\": list(best_arch),\n",
        "            \"best_acts\": list(best_acts),\n",
        "            \"best_loss\": float(best_loss),\n",
        "        })\n",
        "\n",
        "        if verbose:\n",
        "            tag = \"ACCEPT ‚úÖ\" if accepted else \"reject ‚ùå\"\n",
        "            print(\n",
        "                f\"[{t+1:03d}] {tag} | \"\n",
        "                f\"prop_arch={list(prop_arch)} prop_acts={list(prop_acts)} loss={prop_loss:.6f} | \"\n",
        "                f\"cur_arch={list(cur_arch)} cur_acts={list(cur_acts)} cur_loss={cur_loss:.6f} | \"\n",
        "                f\"best_loss={best_loss:.6f} p={acc_prob:.3f}\"\n",
        "            )\n",
        "\n",
        "    return {\n",
        "        \"best_arch\": list(best_arch),\n",
        "        \"best_acts\": list(best_acts),\n",
        "        \"best_loss\": float(best_loss),\n",
        "        \"history\": history,\n",
        "        \"cache_size\": len(cache),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "EWa2E35QSFdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfgE = MCMCConfigE(\n",
        "    K=3,\n",
        "    iters=30,\n",
        "    temperature=0.05,\n",
        "    budget_mode=\"time\",       # –∏–ª–∏ \"epochs\"\n",
        "    train_time_s=0.3,         # –µ—Å–ª–∏ time\n",
        "    train_epochs=50,          # –µ—Å–ª–∏ epochs\n",
        "    p_change_activation=0.30,\n",
        "    allowed_activations=(\"relu\", \"tanh\", \"gelu\", \"sigmoid\"),\n",
        "    dropout=0.1,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    cache=True\n",
        ")\n",
        "\n",
        "init_arch = [32, 32, 32]\n",
        "init_acts = [\"relu\", \"relu\", \"relu\"]\n",
        "\n",
        "resE = metropolis_hastings_search_arch_and_activation(\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    input_dim=input_dim,\n",
        "    output_dim=output_dim,\n",
        "    init_arch=init_arch,\n",
        "    init_acts=init_acts,\n",
        "    cfg=cfgE,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\n=== –ø—É–Ω–∫—Ç (e) –∏—Ç–æ–≥ ===\")\n",
        "print(\"best_arch:\", resE[\"best_arch\"])\n",
        "print(\"best_acts:\", resE[\"best_acts\"])\n",
        "print(\"best_loss:\", resE[\"best_loss\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeOOoa7BSIel",
        "outputId": "15040893-a789-4270-8576-219f3e6423f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start: arch=[32, 32, 32] acts=['relu', 'relu', 'relu'] val_loss=0.599587\n",
            "[001] ACCEPT ‚úÖ | prop_arch=[24, 32, 32] prop_acts=['relu', 'relu', 'relu'] loss=0.600671 | cur_arch=[24, 32, 32] cur_acts=['relu', 'relu', 'relu'] cur_loss=0.600671 | best_loss=0.599587 p=0.979\n",
            "[002] ACCEPT ‚úÖ | prop_arch=[32, 32, 32] prop_acts=['relu', 'relu', 'relu'] loss=0.599587 | cur_arch=[32, 32, 32] cur_acts=['relu', 'relu', 'relu'] cur_loss=0.599587 | best_loss=0.599587 p=1.000\n",
            "[003] reject ‚ùå | prop_arch=[32, 32, 32] prop_acts=['relu', 'relu', 'sigmoid'] loss=0.902975 | cur_arch=[32, 32, 32] cur_acts=['relu', 'relu', 'relu'] cur_loss=0.599587 | best_loss=0.599587 p=0.002\n",
            "[004] reject ‚ùå | prop_arch=[32, 32, 24] prop_acts=['relu', 'relu', 'relu'] loss=0.934116 | cur_arch=[32, 32, 32] cur_acts=['relu', 'relu', 'relu'] cur_loss=0.599587 | best_loss=0.599587 p=0.001\n",
            "[005] ACCEPT ‚úÖ | prop_arch=[32, 32, 40] prop_acts=['relu', 'relu', 'relu'] loss=0.478268 | cur_arch=[32, 32, 40] cur_acts=['relu', 'relu', 'relu'] cur_loss=0.478268 | best_loss=0.478268 p=1.000\n",
            "[006] ACCEPT ‚úÖ | prop_arch=[32, 32, 40] prop_acts=['tanh', 'relu', 'relu'] loss=0.476687 | cur_arch=[32, 32, 40] cur_acts=['tanh', 'relu', 'relu'] cur_loss=0.476687 | best_loss=0.476687 p=1.000\n",
            "[007] ACCEPT ‚úÖ | prop_arch=[32, 32, 48] prop_acts=['tanh', 'relu', 'relu'] loss=0.469962 | cur_arch=[32, 32, 48] cur_acts=['tanh', 'relu', 'relu'] cur_loss=0.469962 | best_loss=0.469962 p=1.000\n",
            "[008] ACCEPT ‚úÖ | prop_arch=[32, 32, 40] prop_acts=['tanh', 'relu', 'relu'] loss=0.476687 | cur_arch=[32, 32, 40] cur_acts=['tanh', 'relu', 'relu'] cur_loss=0.476687 | best_loss=0.469962 p=0.874\n",
            "[009] ACCEPT ‚úÖ | prop_arch=[32, 32, 48] prop_acts=['tanh', 'relu', 'relu'] loss=0.469962 | cur_arch=[32, 32, 48] cur_acts=['tanh', 'relu', 'relu'] cur_loss=0.469962 | best_loss=0.469962 p=1.000\n",
            "[010] reject ‚ùå | prop_arch=[32, 32, 48] prop_acts=['tanh', 'gelu', 'relu'] loss=0.476680 | cur_arch=[32, 32, 48] cur_acts=['tanh', 'relu', 'relu'] cur_loss=0.469962 | best_loss=0.469962 p=0.874\n",
            "[011] ACCEPT ‚úÖ | prop_arch=[32, 32, 40] prop_acts=['tanh', 'relu', 'relu'] loss=0.476687 | cur_arch=[32, 32, 40] cur_acts=['tanh', 'relu', 'relu'] cur_loss=0.476687 | best_loss=0.469962 p=0.874\n",
            "[012] ACCEPT ‚úÖ | prop_arch=[40, 32, 40] prop_acts=['tanh', 'relu', 'relu'] loss=0.466558 | cur_arch=[40, 32, 40] cur_acts=['tanh', 'relu', 'relu'] cur_loss=0.466558 | best_loss=0.466558 p=1.000\n",
            "[013] reject ‚ùå | prop_arch=[40, 32, 48] prop_acts=['tanh', 'relu', 'relu'] loss=0.469487 | cur_arch=[40, 32, 40] cur_acts=['tanh', 'relu', 'relu'] cur_loss=0.466558 | best_loss=0.466558 p=0.943\n",
            "[014] ACCEPT ‚úÖ | prop_arch=[40, 32, 32] prop_acts=['tanh', 'relu', 'relu'] loss=0.474454 | cur_arch=[40, 32, 32] cur_acts=['tanh', 'relu', 'relu'] cur_loss=0.474454 | best_loss=0.466558 p=0.854\n",
            "[015] ACCEPT ‚úÖ | prop_arch=[32, 32, 32] prop_acts=['tanh', 'relu', 'relu'] loss=0.467253 | cur_arch=[32, 32, 32] cur_acts=['tanh', 'relu', 'relu'] cur_loss=0.467253 | best_loss=0.466558 p=1.000\n",
            "[016] ACCEPT ‚úÖ | prop_arch=[32, 32, 24] prop_acts=['tanh', 'relu', 'relu'] loss=0.484496 | cur_arch=[32, 32, 24] cur_acts=['tanh', 'relu', 'relu'] cur_loss=0.484496 | best_loss=0.466558 p=0.708\n",
            "[017] reject ‚ùå | prop_arch=[32, 32, 16] prop_acts=['tanh', 'relu', 'relu'] loss=0.491854 | cur_arch=[32, 32, 24] cur_acts=['tanh', 'relu', 'relu'] cur_loss=0.484496 | best_loss=0.466558 p=0.863\n",
            "[018] ACCEPT ‚úÖ | prop_arch=[32, 32, 24] prop_acts=['tanh', 'tanh', 'relu'] loss=0.461416 | cur_arch=[32, 32, 24] cur_acts=['tanh', 'tanh', 'relu'] cur_loss=0.461416 | best_loss=0.461416 p=1.000\n",
            "[019] reject ‚ùå | prop_arch=[32, 24, 24] prop_acts=['tanh', 'tanh', 'relu'] loss=0.473263 | cur_arch=[32, 32, 24] cur_acts=['tanh', 'tanh', 'relu'] cur_loss=0.461416 | best_loss=0.461416 p=0.789\n",
            "[020] ACCEPT ‚úÖ | prop_arch=[40, 32, 24] prop_acts=['tanh', 'tanh', 'relu'] loss=0.460482 | cur_arch=[40, 32, 24] cur_acts=['tanh', 'tanh', 'relu'] cur_loss=0.460482 | best_loss=0.460482 p=1.000\n",
            "[021] ACCEPT ‚úÖ | prop_arch=[40, 32, 32] prop_acts=['tanh', 'tanh', 'relu'] loss=0.472132 | cur_arch=[40, 32, 32] cur_acts=['tanh', 'tanh', 'relu'] cur_loss=0.472132 | best_loss=0.460482 p=0.792\n",
            "[022] ACCEPT ‚úÖ | prop_arch=[32, 32, 32] prop_acts=['tanh', 'tanh', 'relu'] loss=0.466901 | cur_arch=[32, 32, 32] cur_acts=['tanh', 'tanh', 'relu'] cur_loss=0.466901 | best_loss=0.460482 p=1.000\n",
            "[023] ACCEPT ‚úÖ | prop_arch=[40, 32, 32] prop_acts=['tanh', 'tanh', 'relu'] loss=0.472132 | cur_arch=[40, 32, 32] cur_acts=['tanh', 'tanh', 'relu'] cur_loss=0.472132 | best_loss=0.460482 p=0.901\n",
            "[024] ACCEPT ‚úÖ | prop_arch=[40, 32, 32] prop_acts=['tanh', 'tanh', 'tanh'] loss=0.457287 | cur_arch=[40, 32, 32] cur_acts=['tanh', 'tanh', 'tanh'] cur_loss=0.457287 | best_loss=0.457287 p=1.000\n",
            "[025] ACCEPT ‚úÖ | prop_arch=[48, 32, 32] prop_acts=['tanh', 'tanh', 'tanh'] loss=0.442150 | cur_arch=[48, 32, 32] cur_acts=['tanh', 'tanh', 'tanh'] cur_loss=0.442150 | best_loss=0.442150 p=1.000\n",
            "[026] reject ‚ùå | prop_arch=[48, 24, 32] prop_acts=['tanh', 'tanh', 'tanh'] loss=0.456604 | cur_arch=[48, 32, 32] cur_acts=['tanh', 'tanh', 'tanh'] cur_loss=0.442150 | best_loss=0.442150 p=0.749\n",
            "[027] ACCEPT ‚úÖ | prop_arch=[40, 32, 32] prop_acts=['tanh', 'tanh', 'tanh'] loss=0.457287 | cur_arch=[40, 32, 32] cur_acts=['tanh', 'tanh', 'tanh'] cur_loss=0.457287 | best_loss=0.442150 p=0.739\n",
            "[028] ACCEPT ‚úÖ | prop_arch=[40, 32, 24] prop_acts=['tanh', 'tanh', 'tanh'] loss=0.454263 | cur_arch=[40, 32, 24] cur_acts=['tanh', 'tanh', 'tanh'] cur_loss=0.454263 | best_loss=0.442150 p=1.000\n",
            "[029] ACCEPT ‚úÖ | prop_arch=[40, 40, 24] prop_acts=['tanh', 'tanh', 'tanh'] loss=0.450153 | cur_arch=[40, 40, 24] cur_acts=['tanh', 'tanh', 'tanh'] cur_loss=0.450153 | best_loss=0.442150 p=1.000\n",
            "[030] reject ‚ùå | prop_arch=[40, 40, 24] prop_acts=['tanh', 'tanh', 'gelu'] loss=0.468993 | cur_arch=[40, 40, 24] cur_acts=['tanh', 'tanh', 'tanh'] cur_loss=0.450153 | best_loss=0.442150 p=0.686\n",
            "\n",
            "=== –ø—É–Ω–∫—Ç (e) –∏—Ç–æ–≥ ===\n",
            "best_arch: [48, 32, 32]\n",
            "best_acts: ['tanh', 'tanh', 'tanh']\n",
            "best_loss: 0.44214969323569997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acts_seen = [tuple(h[\"cur_acts\"]) for h in resE[\"history\"]]\n",
        "unique_acts = sorted(set(acts_seen))\n",
        "\n",
        "print(\"–°–∫–æ–ª—å–∫–æ —Ä–∞–∑–Ω—ã—Ö –Ω–∞–±–æ—Ä–æ–≤ –∞–∫—Ç–∏–≤–∞—Ü–∏–π –≤—Å—Ç—Ä–µ—Ç–∏–ª–æ—Å—å:\", len(unique_acts))\n",
        "print(\"–ü—Ä–∏–º–µ—Ä—ã:\", unique_acts[:10])\n",
        "\n",
        "# –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –≤ —Ü–µ–ø–∏ —Ä–µ–∞–ª—å–Ω–æ –º–µ–Ω—è–ª–∏—Å—å –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ (–ø–æ –ø—Ä–∏–Ω—è—Ç—ã–º —à–∞–≥–∞–º)\n",
        "changes = 0\n",
        "prev = tuple([\"relu\",\"relu\",\"relu\"])  # –∏–ª–∏ init_acts\n",
        "for h in resE[\"history\"]:\n",
        "    cur = tuple(h[\"cur_acts\"])\n",
        "    if cur != prev:\n",
        "        changes += 1\n",
        "    prev = cur\n",
        "\n",
        "print(\"–°–∫–æ–ª—å–∫–æ —Ä–∞–∑ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (–∞–∫—Ç–∏–≤–∞—Ü–∏–∏/–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞) –º–µ–Ω—è–ª–æ—Å—å:\", changes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtDdS7ckTjND",
        "outputId": "effadb35-5613-4cf9-ff26-fc99a7a685f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–°–∫–æ–ª—å–∫–æ —Ä–∞–∑–Ω—ã—Ö –Ω–∞–±–æ—Ä–æ–≤ –∞–∫—Ç–∏–≤–∞—Ü–∏–π –≤—Å—Ç—Ä–µ—Ç–∏–ª–æ—Å—å: 7\n",
            "–ü—Ä–∏–º–µ—Ä—ã: [('gelu', 'tanh', 'relu'), ('relu', 'relu', 'relu'), ('relu', 'relu', 'sigmoid'), ('relu', 'tanh', 'gelu'), ('relu', 'tanh', 'relu'), ('relu', 'tanh', 'tanh'), ('tanh', 'tanh', 'relu')]\n",
            "–°–∫–æ–ª—å–∫–æ —Ä–∞–∑ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (–∞–∫—Ç–∏–≤–∞—Ü–∏–∏/–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞) –º–µ–Ω—è–ª–æ—Å—å: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **–ü—É–Ω–∫—Ç F**"
      ],
      "metadata": {
        "id": "qXFRIUYKU1bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Tuple, List, Dict, Any\n",
        "import random, math\n",
        "import numpy as np\n",
        "\n",
        "@dataclass\n",
        "class MCMCConfigF:\n",
        "    # –≥–ª—É–±–∏–Ω–∞ —Ç–µ–ø–µ—Ä—å –ù–ï —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞\n",
        "    min_layers: int = 1          # –º–∏–Ω–∏–º—É–º —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—ë–≤\n",
        "    max_layers: int = 5          # –º–∞–∫—Å–∏–º—É–º —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—ë–≤\n",
        "\n",
        "    # —à–∏—Ä–∏–Ω—ã —Å–ª–æ—ë–≤\n",
        "    min_units: int = 8\n",
        "    max_units: int = 128\n",
        "    step: int = 8\n",
        "\n",
        "    iters: int = 50\n",
        "    temperature: float = 0.05\n",
        "\n",
        "    # –æ–±—É—á–µ–Ω–∏–µ\n",
        "    budget_mode: str = \"time\"    # \"epochs\" | \"time\"\n",
        "    train_epochs: int = 10\n",
        "    train_time_s: float = 0.3\n",
        "\n",
        "    lr: float = 1e-3\n",
        "    weight_decay: float = 1e-4\n",
        "    dropout: float = 0.1\n",
        "\n",
        "    # –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ (–∫–∞–∫ –≤ e)\n",
        "    allowed_activations: Tuple[str, ...] = (\"relu\", \"tanh\", \"gelu\", \"sigmoid\")\n",
        "\n",
        "    # –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ç–∏–ø–æ–≤ —à–∞–≥–æ–≤ (—Å—É–º–º–∞ = 1)\n",
        "    p_width_move: float = 0.55\n",
        "    p_act_move: float = 0.25\n",
        "    p_depth_move: float = 0.20\n",
        "\n",
        "    cache: bool = True\n",
        "    seed_base: int = 12345\n"
      ],
      "metadata": {
        "id": "0wVD0IrqU3mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _depth_add_remove_probs(k: int, cfg: MCMCConfigF) -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—ã–±—Ä–∞—Ç—å ADD/REMOVE –≤–Ω—É—Ç—Ä–∏ depth-move —Å —É—á—ë—Ç–æ–º –≥—Ä–∞–Ω–∏—Ü.\n",
        "    \"\"\"\n",
        "    if k <= cfg.min_layers:\n",
        "        return 1.0, 0.0  # –º–æ–∂–Ω–æ —Ç–æ–ª—å–∫–æ –¥–æ–±–∞–≤–∏—Ç—å\n",
        "    if k >= cfg.max_layers:\n",
        "        return 0.0, 1.0  # –º–æ–∂–Ω–æ —Ç–æ–ª—å–∫–æ —É–¥–∞–ª–∏—Ç—å\n",
        "    return 0.5, 0.5      # –∏–Ω–∞—á–µ –ø–æ—Ä–æ–≤–Ω—É\n",
        "\n",
        "\n",
        "def _width_choices(cfg: MCMCConfigF) -> List[int]:\n",
        "    # –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–π –Ω–∞–±–æ—Ä —à–∏—Ä–∏–Ω (—á—Ç–æ–±—ã –æ–±—Ä–∞—Ç–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Å—á–∏—Ç–∞–ª–∏—Å—å —Ä–æ–≤–Ω–æ)\n",
        "    return list(range(cfg.min_units, cfg.max_units + 1, cfg.step))\n",
        "\n",
        "\n",
        "def propose_state_depth(\n",
        "    arch: Tuple[int, ...],\n",
        "    acts: Tuple[str, ...],\n",
        "    cfg: MCMCConfigF\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict:\n",
        "      - new_arch, new_acts\n",
        "      - move_type\n",
        "      - q_fwd, q_rev (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤–ø–µ—Ä—ë–¥/–Ω–∞–∑–∞–¥)\n",
        "    \"\"\"\n",
        "    k = len(arch)\n",
        "    assert k == len(acts)\n",
        "\n",
        "    # –≤—ã–±–∏—Ä–∞–µ–º —Ç–∏–ø —à–∞–≥–∞\n",
        "    r = random.random()\n",
        "    if r < cfg.p_width_move:\n",
        "        move_type = \"width\"\n",
        "    elif r < cfg.p_width_move + cfg.p_act_move:\n",
        "        move_type = \"act\"\n",
        "    else:\n",
        "        move_type = \"depth\"\n",
        "\n",
        "    # ---------- 1) WIDTH MOVE (—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π) ----------\n",
        "    if move_type == \"width\":\n",
        "        i = random.randrange(k)\n",
        "        direction = random.choice([-1, +1])\n",
        "        cand = arch[i] + direction * cfg.step\n",
        "\n",
        "        # –Ω—É–ª–µ–≤–æ–π —Ö–æ–¥ –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã\n",
        "        if cand < cfg.min_units or cand > cfg.max_units:\n",
        "            return {\"new_arch\": arch, \"new_acts\": acts, \"move_type\": \"width_null\", \"q_fwd\": 1.0, \"q_rev\": 1.0}\n",
        "\n",
        "        new_arch = list(arch)\n",
        "        new_arch[i] = int(cand)\n",
        "\n",
        "        # –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö —Ö–æ–¥–æ–≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç—É–¥–∞ –∏ –æ–±—Ä–∞—Ç–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤–∞—è\n",
        "        return {\"new_arch\": tuple(new_arch), \"new_acts\": acts, \"move_type\": \"width\", \"q_fwd\": 1.0, \"q_rev\": 1.0}\n",
        "\n",
        "    # ---------- 2) ACT MOVE (—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π) ----------\n",
        "    if move_type == \"act\":\n",
        "        i = random.randrange(k)\n",
        "        cur = acts[i]\n",
        "        candidates = [a for a in cfg.allowed_activations if a != cur]\n",
        "        if not candidates:\n",
        "            return {\"new_arch\": arch, \"new_acts\": acts, \"move_type\": \"act_null\", \"q_fwd\": 1.0, \"q_rev\": 1.0}\n",
        "\n",
        "        new_act = random.choice(candidates)\n",
        "        new_acts = list(acts)\n",
        "        new_acts[i] = new_act\n",
        "\n",
        "        return {\"new_arch\": arch, \"new_acts\": tuple(new_acts), \"move_type\": \"act\", \"q_fwd\": 1.0, \"q_rev\": 1.0}\n",
        "\n",
        "    # ---------- 3) DEPTH MOVE (ADD/REMOVE, —É—á–∏—Ç—ã–≤–∞–µ–º q_rev/q_fwd) ----------\n",
        "    add_p, rem_p = _depth_add_remove_probs(k, cfg)\n",
        "    widths = _width_choices(cfg)\n",
        "    W = len(widths)\n",
        "    A = len(cfg.allowed_activations)\n",
        "\n",
        "    # –µ—Å–ª–∏ –≤—ã–±–æ—Ä–∞ –Ω–µ—Ç (–Ω–∞ –≤—Å—è–∫–∏–π)\n",
        "    if add_p == 0.0 and rem_p == 0.0:\n",
        "        return {\"new_arch\": arch, \"new_acts\": acts, \"move_type\": \"depth_null\", \"q_fwd\": 1.0, \"q_rev\": 1.0}\n",
        "\n",
        "    # decide add/remove\n",
        "    u = random.random()\n",
        "    do_add = (u < add_p)\n",
        "\n",
        "    # --- ADD LAYER ---\n",
        "    if do_add:\n",
        "        # –≤—ã–±–∏—Ä–∞–µ–º –ø–æ–∑–∏—Ü–∏—é –≤—Å—Ç–∞–≤–∫–∏ (k+1 –≤–æ–∑–º–æ–∂–Ω—ã—Ö)\n",
        "        pos = random.randrange(k + 1)\n",
        "        w_new = random.choice(widths)\n",
        "        a_new = random.choice(cfg.allowed_activations)\n",
        "\n",
        "        new_arch = list(arch)\n",
        "        new_acts = list(acts)\n",
        "        new_arch.insert(pos, w_new)\n",
        "        new_acts.insert(pos, a_new)\n",
        "\n",
        "        k_new = k + 1\n",
        "\n",
        "        # q_forward = P(depth)*P(add|k)*P(pos)*P(width)*P(act)\n",
        "        q_fwd = cfg.p_depth_move * add_p * (1.0 / (k + 1)) * (1.0 / W) * (1.0 / A)\n",
        "\n",
        "        # –æ–±—Ä–∞—Ç–Ω—ã–π —Ö–æ–¥: –∏–∑ k+1 —Å–ª–æ—ë–≤ —É–¥–∞–ª–∏—Ç—å –∏–º–µ–Ω–Ω–æ –≤—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Å–ª–æ–π (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å 1/(k+1))\n",
        "        add_p_back, rem_p_back = _depth_add_remove_probs(k_new, cfg)\n",
        "        q_rev = cfg.p_depth_move * rem_p_back * (1.0 / (k_new))\n",
        "\n",
        "        return {\n",
        "            \"new_arch\": tuple(new_arch),\n",
        "            \"new_acts\": tuple(new_acts),\n",
        "            \"move_type\": \"depth_add\",\n",
        "            \"q_fwd\": q_fwd,\n",
        "            \"q_rev\": q_rev\n",
        "        }\n",
        "\n",
        "    # --- REMOVE LAYER ---\n",
        "    else:\n",
        "        # —É–¥–∞–ª–∏—Ç—å –º–æ–∂–Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ k > min_layers (–≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ rem_p>0)\n",
        "        pos = random.randrange(k)\n",
        "        w_removed = arch[pos]\n",
        "        a_removed = acts[pos]\n",
        "\n",
        "        new_arch = list(arch)\n",
        "        new_acts = list(acts)\n",
        "        new_arch.pop(pos)\n",
        "        new_acts.pop(pos)\n",
        "\n",
        "        k_new = k - 1\n",
        "\n",
        "        # q_forward = P(depth)*P(remove|k)*P(pos)\n",
        "        q_fwd = cfg.p_depth_move * rem_p * (1.0 / k)\n",
        "\n",
        "        # –æ–±—Ä–∞—Ç–Ω—ã–π —Ö–æ–¥: –∏–∑ k-1 –≤—Å—Ç–∞–≤–∏—Ç—å –Ω–∞ –Ω—É–∂–Ω—É—é –ø–æ–∑–∏—Ü–∏—é –Ω—É–∂–Ω—É—é —à–∏—Ä–∏–Ω—É/–∞–∫—Ç–∏–≤–∞—Ü–∏—é\n",
        "        add_p_back, rem_p_back = _depth_add_remove_probs(k_new, cfg)\n",
        "        q_rev = cfg.p_depth_move * add_p_back * (1.0 / (k_new + 1)) * (1.0 / W) * (1.0 / A)\n",
        "\n",
        "        return {\n",
        "            \"new_arch\": tuple(new_arch),\n",
        "            \"new_acts\": tuple(new_acts),\n",
        "            \"move_type\": \"depth_remove\",\n",
        "            \"q_fwd\": q_fwd,\n",
        "            \"q_rev\": q_rev\n",
        "        }\n"
      ],
      "metadata": {
        "id": "7_UPUvpKW433"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metropolis_hastings_depth_search(\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    input_dim: int,\n",
        "    output_dim: int,\n",
        "    init_arch: List[int],\n",
        "    init_acts: List[str],\n",
        "    cfg: MCMCConfigF,\n",
        "    verbose: bool = True\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    assert len(init_arch) == len(init_acts)\n",
        "    assert cfg.min_layers <= len(init_arch) <= cfg.max_layers\n",
        "\n",
        "    cache: Dict[Tuple[Tuple[int, ...], Tuple[str, ...]], Dict[str, Any]] = {}\n",
        "\n",
        "    def get_eval(arch_t: Tuple[int, ...], acts_t: Tuple[str, ...]) -> Dict[str, Any]:\n",
        "        key = (arch_t, acts_t)\n",
        "        if cfg.cache and key in cache:\n",
        "            out = cache[key].copy()\n",
        "            out[\"_cached\"] = True\n",
        "            return out\n",
        "\n",
        "        seed_for_state = cfg.seed_base + (abs(hash(key)) % 100000)\n",
        "\n",
        "        out = train_and_get_val_loss_budget(\n",
        "            arch=list(arch_t),\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            input_dim=input_dim,\n",
        "            output_dim=output_dim,\n",
        "            activation=list(acts_t),      # —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–∞—Ü–∏–π –ø–æ —Å–ª–æ—è–º\n",
        "            dropout=cfg.dropout,\n",
        "            lr=cfg.lr,\n",
        "            weight_decay=cfg.weight_decay,\n",
        "            budget_mode=cfg.budget_mode,\n",
        "            train_epochs=cfg.train_epochs,\n",
        "            train_time_s=cfg.train_time_s,\n",
        "            seed_for_arch=seed_for_state\n",
        "        )\n",
        "        out[\"_cached\"] = False\n",
        "\n",
        "        if cfg.cache:\n",
        "            cache[key] = out\n",
        "        return out\n",
        "\n",
        "    cur_arch = tuple(int(x) for x in init_arch)\n",
        "    cur_acts = tuple(str(a).lower() for a in init_acts)\n",
        "\n",
        "    cur_eval = get_eval(cur_arch, cur_acts)\n",
        "    cur_loss = float(cur_eval[\"val_loss\"])\n",
        "\n",
        "    best_arch, best_acts, best_loss = cur_arch, cur_acts, cur_loss\n",
        "\n",
        "    history: List[Dict[str, Any]] = []\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Start: depth={len(cur_arch)} arch={list(cur_arch)} acts={list(cur_acts)} loss={cur_loss:.6f}\")\n",
        "\n",
        "    for t in range(cfg.iters):\n",
        "        prop = propose_state_depth(cur_arch, cur_acts, cfg)\n",
        "        prop_arch = prop[\"new_arch\"]\n",
        "        prop_acts = prop[\"new_acts\"]\n",
        "\n",
        "        prop_eval = get_eval(prop_arch, prop_acts)\n",
        "        prop_loss = float(prop_eval[\"val_loss\"])\n",
        "\n",
        "        # MH acceptance —Å —É—á–µ—Ç–æ–º q_rev/q_fwd (–≤–∞–∂–Ω–æ –∏–º–µ–Ω–Ω–æ –¥–ª—è depth_add/depth_remove)\n",
        "        T = max(cfg.temperature, 1e-12)\n",
        "        log_accept = -(prop_loss - cur_loss) / T\n",
        "\n",
        "        q_fwd = float(prop.get(\"q_fwd\", 1.0))\n",
        "        q_rev = float(prop.get(\"q_rev\", 1.0))\n",
        "        # –∑–∞—â–∏—Ç–∞ –æ—Ç –Ω—É–ª–µ–π\n",
        "        q_fwd = max(q_fwd, 1e-300)\n",
        "        q_rev = max(q_rev, 1e-300)\n",
        "        log_accept += math.log(q_rev) - math.log(q_fwd)\n",
        "\n",
        "        acc_prob = min(1.0, math.exp(log_accept))\n",
        "        accepted = (random.random() < acc_prob)\n",
        "\n",
        "        if accepted:\n",
        "            cur_arch, cur_acts, cur_loss = prop_arch, prop_acts, prop_loss\n",
        "\n",
        "        if cur_loss < best_loss:\n",
        "            best_arch, best_acts, best_loss = cur_arch, cur_acts, cur_loss\n",
        "\n",
        "        history.append({\n",
        "            \"iter\": t + 1,\n",
        "            \"move_type\": prop[\"move_type\"],\n",
        "            \"accepted\": bool(accepted),\n",
        "            \"acc_prob\": float(acc_prob),\n",
        "\n",
        "            \"cur_depth\": len(cur_arch),\n",
        "            \"cur_arch\": list(cur_arch),\n",
        "            \"cur_acts\": list(cur_acts),\n",
        "            \"cur_loss\": float(cur_loss),\n",
        "\n",
        "            \"prop_depth\": len(prop_arch),\n",
        "            \"prop_arch\": list(prop_arch),\n",
        "            \"prop_acts\": list(prop_acts),\n",
        "            \"prop_loss\": float(prop_loss),\n",
        "\n",
        "            \"epochs_done\": int(prop_eval.get(\"epochs_done\", -1)),\n",
        "            \"train_seconds\": float(prop_eval.get(\"train_seconds\", 0.0)),\n",
        "            \"_cached\": bool(prop_eval.get(\"_cached\", False)),\n",
        "\n",
        "            \"best_depth\": len(best_arch),\n",
        "            \"best_arch\": list(best_arch),\n",
        "            \"best_acts\": list(best_acts),\n",
        "            \"best_loss\": float(best_loss),\n",
        "        })\n",
        "\n",
        "        if verbose:\n",
        "            tag = \"ACCEPT ‚úÖ\" if accepted else \"reject ‚ùå\"\n",
        "            print(\n",
        "                f\"[{t+1:03d}] {tag} {prop['move_type']} | \"\n",
        "                f\"prop_depth={len(prop_arch)} loss={prop_loss:.6f} -> \"\n",
        "                f\"cur_depth={len(cur_arch)} loss={cur_loss:.6f} | \"\n",
        "                f\"best={best_loss:.6f} p={acc_prob:.3f}\"\n",
        "            )\n",
        "\n",
        "    return {\n",
        "        \"best_arch\": list(best_arch),\n",
        "        \"best_acts\": list(best_acts),\n",
        "        \"best_depth\": len(best_arch),\n",
        "        \"best_loss\": float(best_loss),\n",
        "        \"history\": history,\n",
        "        \"cache_size\": len(cache),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "0J2Y-9DkW7PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfgF = MCMCConfigF(\n",
        "    min_layers=1,\n",
        "    max_layers=5,\n",
        "    iters=60,\n",
        "    temperature=0.005,\n",
        "    budget_mode=\"time\",\n",
        "    train_time_s=0.3,\n",
        "\n",
        "    # –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —à–∞–≥–æ–≤\n",
        "    p_width_move=0.50,\n",
        "    p_act_move=0.20,\n",
        "    p_depth_move=0.30,\n",
        "\n",
        "    allowed_activations=(\"relu\", \"tanh\", \"gelu\", \"sigmoid\"),\n",
        "    dropout=0.1,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    cache=True\n",
        ")\n",
        "\n",
        "# —Å—Ç–∞—Ä—Ç—É–µ–º, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å –≥–ª—É–±–∏–Ω—ã 3\n",
        "init_arch = [32, 32, 32]\n",
        "init_acts = [\"relu\", \"tanh\", \"gelu\"]   # –º–æ–∂–Ω–æ –∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ ‚Äî –≥–ª—É–±–∏–Ω–∞ –≤—Å—ë —Ä–∞–≤–Ω–æ –±—É–¥–µ—Ç –º–µ–Ω—è—Ç—å—Å—è\n",
        "\n",
        "resF = metropolis_hastings_depth_search(\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    input_dim=input_dim,\n",
        "    output_dim=output_dim,\n",
        "    init_arch=init_arch,\n",
        "    init_acts=init_acts,\n",
        "    cfg=cfgF,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\n=== –ø—É–Ω–∫—Ç (f) –∏—Ç–æ–≥ ===\")\n",
        "print(\"best_depth:\", resF[\"best_depth\"])\n",
        "print(\"best_arch :\", resF[\"best_arch\"])\n",
        "print(\"best_acts :\", resF[\"best_acts\"])\n",
        "print(\"best_loss :\", resF[\"best_loss\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF-4VfoJW-TJ",
        "outputId": "e0477c0b-5d24-439c-dcb3-6fe9ae50e5b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start: depth=3 arch=[32, 32, 32] acts=['relu', 'tanh', 'gelu'] loss=0.495836\n",
            "[001] ACCEPT ‚úÖ act | prop_depth=3 loss=0.464683 -> cur_depth=3 loss=0.464683 | best=0.464683 p=1.000\n",
            "[002] reject ‚ùå act | prop_depth=3 loss=0.476014 -> cur_depth=3 loss=0.464683 | best=0.464683 p=0.868\n",
            "[003] reject ‚ùå act | prop_depth=3 loss=0.489259 -> cur_depth=3 loss=0.464683 | best=0.464683 p=0.736\n",
            "[004] reject ‚ùå depth_remove | prop_depth=2 loss=0.476880 -> cur_depth=3 loss=0.464683 | best=0.464683 p=0.013\n",
            "[005] ACCEPT ‚úÖ width | prop_depth=3 loss=0.470320 -> cur_depth=3 loss=0.470320 | best=0.464683 p=0.932\n",
            "[006] ACCEPT ‚úÖ act | prop_depth=3 loss=0.452347 -> cur_depth=3 loss=0.452347 | best=0.452347 p=1.000\n",
            "[007] reject ‚ùå width | prop_depth=3 loss=0.465787 -> cur_depth=3 loss=0.452347 | best=0.452347 p=0.845\n",
            "[008] ACCEPT ‚úÖ act | prop_depth=3 loss=0.470320 -> cur_depth=3 loss=0.470320 | best=0.452347 p=0.799\n",
            "[009] ACCEPT ‚úÖ act | prop_depth=3 loss=0.487841 -> cur_depth=3 loss=0.487841 | best=0.452347 p=0.803\n",
            "[010] ACCEPT ‚úÖ width | prop_depth=3 loss=0.476363 -> cur_depth=3 loss=0.476363 | best=0.452347 p=1.000\n",
            "[011] ACCEPT ‚úÖ width | prop_depth=3 loss=0.492215 -> cur_depth=3 loss=0.492215 | best=0.452347 p=0.820\n",
            "[012] reject ‚ùå depth_remove | prop_depth=2 loss=0.458813 -> cur_depth=3 loss=0.492215 | best=0.452347 p=0.024\n",
            "[013] ACCEPT ‚úÖ act | prop_depth=3 loss=0.466885 -> cur_depth=3 loss=0.466885 | best=0.452347 p=1.000\n",
            "[014] ACCEPT ‚úÖ width | prop_depth=3 loss=0.467513 -> cur_depth=3 loss=0.467513 | best=0.452347 p=0.992\n",
            "[015] ACCEPT ‚úÖ depth_add | prop_depth=4 loss=0.511629 -> cur_depth=4 loss=0.511629 | best=0.452347 p=1.000\n",
            "[016] ACCEPT ‚úÖ act | prop_depth=4 loss=0.516118 -> cur_depth=4 loss=0.516118 | best=0.452347 p=0.945\n",
            "[017] ACCEPT ‚úÖ width | prop_depth=4 loss=0.524568 -> cur_depth=4 loss=0.524568 | best=0.452347 p=0.900\n",
            "[018] ACCEPT ‚úÖ depth_add | prop_depth=5 loss=0.515971 -> cur_depth=5 loss=0.515971 | best=0.452347 p=1.000\n",
            "[019] ACCEPT ‚úÖ width | prop_depth=5 loss=0.534303 -> cur_depth=5 loss=0.534303 | best=0.452347 p=0.795\n",
            "[020] ACCEPT ‚úÖ width | prop_depth=5 loss=0.526266 -> cur_depth=5 loss=0.526266 | best=0.452347 p=1.000\n",
            "[021] ACCEPT ‚úÖ width | prop_depth=5 loss=0.515101 -> cur_depth=5 loss=0.515101 | best=0.452347 p=1.000\n",
            "[022] ACCEPT ‚úÖ width | prop_depth=5 loss=0.523395 -> cur_depth=5 loss=0.523395 | best=0.452347 p=0.902\n",
            "[023] ACCEPT ‚úÖ width | prop_depth=5 loss=0.520380 -> cur_depth=5 loss=0.520380 | best=0.452347 p=1.000\n",
            "[024] ACCEPT ‚úÖ act | prop_depth=5 loss=0.539927 -> cur_depth=5 loss=0.539927 | best=0.452347 p=0.783\n",
            "[025] reject ‚ùå depth_remove | prop_depth=4 loss=0.519691 -> cur_depth=5 loss=0.539927 | best=0.452347 p=0.010\n",
            "[026] reject ‚ùå depth_remove | prop_depth=4 loss=0.498942 -> cur_depth=5 loss=0.539927 | best=0.452347 p=0.013\n",
            "[027] ACCEPT ‚úÖ act | prop_depth=5 loss=0.513994 -> cur_depth=5 loss=0.513994 | best=0.452347 p=1.000\n",
            "[028] ACCEPT ‚úÖ width | prop_depth=5 loss=0.497844 -> cur_depth=5 loss=0.497844 | best=0.452347 p=1.000\n",
            "[029] ACCEPT ‚úÖ width | prop_depth=5 loss=0.496636 -> cur_depth=5 loss=0.496636 | best=0.452347 p=1.000\n",
            "[030] ACCEPT ‚úÖ width | prop_depth=5 loss=0.513527 -> cur_depth=5 loss=0.513527 | best=0.452347 p=0.810\n",
            "[031] reject ‚ùå depth_remove | prop_depth=4 loss=0.499046 -> cur_depth=5 loss=0.513527 | best=0.452347 p=0.009\n",
            "[032] ACCEPT ‚úÖ width | prop_depth=5 loss=0.510377 -> cur_depth=5 loss=0.510377 | best=0.452347 p=1.000\n",
            "[033] reject ‚ùå depth_remove | prop_depth=4 loss=0.464868 -> cur_depth=5 loss=0.510377 | best=0.452347 p=0.014\n",
            "[034] ACCEPT ‚úÖ width | prop_depth=5 loss=0.537969 -> cur_depth=5 loss=0.537969 | best=0.452347 p=0.708\n",
            "[035] reject ‚ùå depth_remove | prop_depth=4 loss=0.480040 -> cur_depth=5 loss=0.537969 | best=0.452347 p=0.016\n",
            "[036] ACCEPT ‚úÖ width | prop_depth=5 loss=0.522633 -> cur_depth=5 loss=0.522633 | best=0.452347 p=1.000\n",
            "[037] reject ‚ùå act | prop_depth=5 loss=0.587173 -> cur_depth=5 loss=0.522633 | best=0.452347 p=0.446\n",
            "[038] ACCEPT ‚úÖ width | prop_depth=5 loss=0.515701 -> cur_depth=5 loss=0.515701 | best=0.452347 p=1.000\n",
            "[039] reject ‚ùå width | prop_depth=5 loss=0.531155 -> cur_depth=5 loss=0.515701 | best=0.452347 p=0.824\n",
            "[040] ACCEPT ‚úÖ width | prop_depth=5 loss=0.522633 -> cur_depth=5 loss=0.522633 | best=0.452347 p=0.917\n",
            "[041] reject ‚ùå depth_remove | prop_depth=4 loss=0.495557 -> cur_depth=5 loss=0.522633 | best=0.452347 p=0.011\n",
            "[042] ACCEPT ‚úÖ width | prop_depth=5 loss=0.539034 -> cur_depth=5 loss=0.539034 | best=0.452347 p=0.815\n",
            "[043] reject ‚ùå depth_remove | prop_depth=4 loss=0.467717 -> cur_depth=5 loss=0.539034 | best=0.452347 p=0.019\n",
            "[044] reject ‚ùå depth_remove | prop_depth=4 loss=0.474763 -> cur_depth=5 loss=0.539034 | best=0.452347 p=0.017\n",
            "[045] ACCEPT ‚úÖ act | prop_depth=5 loss=0.541472 -> cur_depth=5 loss=0.541472 | best=0.452347 p=0.970\n",
            "[046] ACCEPT ‚úÖ act | prop_depth=5 loss=0.543555 -> cur_depth=5 loss=0.543555 | best=0.452347 p=0.974\n",
            "[047] reject ‚ùå depth_remove | prop_depth=4 loss=0.537488 -> cur_depth=5 loss=0.543555 | best=0.452347 p=0.008\n",
            "[048] ACCEPT ‚úÖ act | prop_depth=5 loss=0.533464 -> cur_depth=5 loss=0.533464 | best=0.452347 p=1.000\n",
            "[049] ACCEPT ‚úÖ width | prop_depth=5 loss=0.550898 -> cur_depth=5 loss=0.550898 | best=0.452347 p=0.804\n",
            "[050] ACCEPT ‚úÖ width | prop_depth=5 loss=0.548616 -> cur_depth=5 loss=0.548616 | best=0.452347 p=1.000\n",
            "[051] ACCEPT ‚úÖ act | prop_depth=5 loss=0.550054 -> cur_depth=5 loss=0.550054 | best=0.452347 p=0.982\n",
            "[052] reject ‚ùå depth_remove | prop_depth=4 loss=0.495737 -> cur_depth=5 loss=0.550054 | best=0.452347 p=0.015\n",
            "[053] ACCEPT ‚úÖ width | prop_depth=5 loss=0.541435 -> cur_depth=5 loss=0.541435 | best=0.452347 p=1.000\n",
            "[054] reject ‚ùå act | prop_depth=5 loss=0.600274 -> cur_depth=5 loss=0.541435 | best=0.452347 p=0.479\n",
            "[055] ACCEPT ‚úÖ act | prop_depth=5 loss=0.531585 -> cur_depth=5 loss=0.531585 | best=0.452347 p=1.000\n",
            "[056] ACCEPT ‚úÖ act | prop_depth=5 loss=0.526626 -> cur_depth=5 loss=0.526626 | best=0.452347 p=1.000\n",
            "[057] reject ‚ùå depth_remove | prop_depth=4 loss=0.518010 -> cur_depth=5 loss=0.526626 | best=0.452347 p=0.009\n",
            "[058] ACCEPT ‚úÖ width | prop_depth=5 loss=0.529881 -> cur_depth=5 loss=0.529881 | best=0.452347 p=0.960\n",
            "[059] ACCEPT ‚úÖ width | prop_depth=5 loss=0.528829 -> cur_depth=5 loss=0.528829 | best=0.452347 p=1.000\n",
            "[060] ACCEPT ‚úÖ act | prop_depth=5 loss=0.508505 -> cur_depth=5 loss=0.508505 | best=0.452347 p=1.000\n",
            "\n",
            "=== –ø—É–Ω–∫—Ç (f) –∏—Ç–æ–≥ ===\n",
            "best_depth: 3\n",
            "best_arch : [32, 32, 40]\n",
            "best_acts : ['tanh', 'tanh', 'tanh']\n",
            "best_loss : 0.45234735073638577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "depths = [h[\"cur_depth\"] for h in resF[\"history\"]]\n",
        "print(\"–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–ª—É–±–∏–Ω—ã –≤ —Ü–µ–ø–∏:\", sorted(set(depths)))\n",
        "print(\"–°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –±—ã–ª depth-move:\", sum(\"depth\" in h[\"move_type\"] for h in resF[\"history\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qmw3EQ8XCO7",
        "outputId": "7b831371-9ea6-49d4-85a8-09af6474a025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–ª—É–±–∏–Ω—ã –≤ —Ü–µ–ø–∏: [3, 4, 5]\n",
            "–°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –±—ã–ª depth-move: 15\n"
          ]
        }
      ]
    }
  ]
}